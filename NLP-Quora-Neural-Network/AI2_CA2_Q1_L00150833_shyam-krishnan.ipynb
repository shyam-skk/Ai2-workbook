{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing CA 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shyam Krishnan k - L00150833 <br>\n",
    "MSc in Big Data Analytics and Artificial Intelligence <br>\n",
    "Artificial Intelligence 2 <br>\n",
    "Assignment - NLP CA 2 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os library is using for accessing operating system dependent functionality\n",
    "import os\n",
    "# pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "# random module using to generate pseudo-random numbers\n",
    "import random\n",
    "# numpy is using to manipulate multi-dimensional arrays and matrices. Also support mathematical functions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808578"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('quora_questions.csv') # rading the data into a data frame.\n",
    "len(df)                               # returns number of rows in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read the all the data in the quora_questions in to a pandas dataframe using Let's read the data (using read_csv).\n",
    "The data set is consists of 808578."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to generate 200000 permenent random data sample from the df dataframe including the header.\n",
    "dataframe = df.sample(n=200001, random_state=123)\n",
    "len(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas sample() is used to generate a sample random row or column from data frame. Here n is a int value which  defines the number of random rows to generate. The \"random_state\" is to check and validate the data when running the code multiple times. Setting random_state a fixed value will guarantee that same sequence of random numbers are generated each time you run the code. And unless there is some other randomness present in the process, the results produced will be same as always. This helps in verifying the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>528339</th>\n",
       "      <td>How do I hack a wifi?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161450</th>\n",
       "      <td>Wwe is real fight?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699472</th>\n",
       "      <td>What is written in vedas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736752</th>\n",
       "      <td>Why don't women propose to men in India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772144</th>\n",
       "      <td>Which car should I buy for my parents in India?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question\n",
       "528339                            How do I hack a wifi?\n",
       "161450                               Wwe is real fight?\n",
       "699472                        What is written in vedas?\n",
       "736752         Why don't women propose to men in India?\n",
       "772144  Which car should I buy for my parents in India?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head() # returns first 5 lines of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256607</th>\n",
       "      <td>What is an inclined plane? What are examples o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300740</th>\n",
       "      <td>How can I prove that a negative number multipl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531674</th>\n",
       "      <td>How do I learn English step by step?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139362</th>\n",
       "      <td>In what ways are you privileged and in what wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702490</th>\n",
       "      <td>Is time travel possible? If yes how</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question\n",
       "256607  What is an inclined plane? What are examples o...\n",
       "300740  How can I prove that a negative number multipl...\n",
       "531674               How do I learn English step by step?\n",
       "139362  In what ways are you privileged and in what wa...\n",
       "702490                Is time travel possible? If yes how"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.tail() # returns last 5 lines of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200001, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.shape) # return the number of rows and columns in the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame is consisits of 200001 rows and 1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['question'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns) # return the column names in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is an inclined plane? What are examples of this?\n"
     ]
    }
   ],
   "source": [
    "# printing a random question in the index position 256607\n",
    "print(dataframe['question'][256607])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer is using to split up the data ie questions into a list of words(a spare matrix with count of each word). ount vectorizer builds a dictionary of features and transforms documents to feature vectors. It is also called one-hot encoding. It is the most basic and simple way of representing text data numerically. Here we will create vectors that have a dimensionality equal to the size of our vocabulary. Each text data featire will be represented using one and when we encounter that word again, we will increase the count, leaving 0s everywhere we did not find the word even once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import count vectorizer from Scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here fwe will pass the data into a count vectorizer and then transform the question data.\n",
    "This is performed in two steps.\n",
    "1. First initiate the model with fine tuned appropriate parameters.\n",
    "2. Fit the model with the data and transform it into vectors.\n",
    "\n",
    "In the second setp first we builds vocabulary and counts number of words the questions. Then transform vocabulary of words in the questions to a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise an instance of the count vectorizer\n",
    "count_vectorizer = CountVectorizer(max_df=0.70, min_df=4, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will initialise an instance of the count vectorizer using two variables - max_df and min_df. These parameters are using to define the minimum and maximum number of words we should ignore within our documents. The max_df option accepts a float in range ( 0, 1 ), max_df will ignore terms that have a document frequency strictly higher than the given threshold. The min_df will remove the terms that have a frequency lower than the given threshold in the vocabulary. The min_df can be expressed as float in the range (0, 1) or as an intiger value of minimum occurence.\n",
    "\n",
    "Here in this example iam using 0.7 as max_df and intiger value 4 as min_df.\n",
    "\n",
    "The data frame created from quora questions contain 200000 questons asked in the platform. The max_df is set to 0.7 becase i want to remove all major and minor stop words used in the dataset. From the primery analysis of the data set it is clear that all questions in the data set is starting with various Question Words, which is not useful in the context of classification. So to remove all major Question Words and stop words i choose a lower value for max_df.\n",
    "\n",
    "It is also clear that many of the questions included in the data set is simple one sentence questions. So there is a higher possibility of having unique words that is not much repeated the questions.Here min_df is set to 4 because I want to remove the words that is not present in atleast 4 questions for better topic selection and classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and then transforms data into a numerical vector\n",
    "doc_term_matrix = count_vectorizer.fit_transform(dataframe[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200001x17114 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 964821 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The doc_term_matrix is a sparse matrix of each word in all of the text data. Here the doc_term_matrix contains 200000 rows of questions data and 7155 columns or features corrsponding to rows. Adjusting the max_df and min_df values can increase or decrease the number of terms in the doc_term_matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation - Model -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Dirichlet allocation (LDA) is a method of automatically discovering topics from the sentences. A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule. LDA represents documents as mixtures of topics that contains set of words with certain probabilities. In Natural Language Processing topic modelling is defined as the process of uncovering hidden structure in a collection of texts. It is a unsupervised mothod using on a collection of text or documents to  group similar words within text together in order to classfy the documents in to topic. LDA spot the semantic relationship between words and group them with the help of associated indicators. To LDA, a document is just a collection of topics where  each topic has some particular probability of generating a certain word.\n",
    "\n",
    "LDA will represent each questions as a list of probability of topics based on the vocabulary used in it. Each topic will represented as a certain weight which indicates which topic it most likely should be in and we will select topic with heigher weight or probability from the list of weights. Here i will train and fit the LDA model on the dataset by clustering the words based on the correlations between word counts and create categories of words with a certain frequency to determine the specific category based on the common words found within it.\n",
    "\n",
    "The number of topic is choosed by a  hyperparameter - n_components. For each topic, LDA will pick a distribution of words for that topic. The word ‘topic’ refers to associating a certain word to with a definition. Here in my first model i am initialise an instance of the LDA model by setting n_components = 15 ie we are trying to create a pool of 15 topics with list of correlated words from each text. \n",
    "\n",
    "If the optput list of topics contains large number of similar words in each topics we need to reduce the number of topics and rerun the model. If each topic list contains multiple uncorelated words with in each topic, then we need to increase the number of n_components and rerun the model to create a better model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing LDA from Scikit-learn\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise an instance of the LDA.\n",
    "lda = LatentDirichletAllocation(n_components=15,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=15, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=1, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with doc_term_matrix\n",
    "lda.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i fit my LDA model on doc_term_matrix with following parameters\n",
    "n_components=15 and random_state=1. All other parameters are set to default value.\n",
    "\n",
    "random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random ( default value is None)\n",
    "\n",
    "learning_decay is a another importent parameter. Its a flot value with default as 0.7.\n",
    "It is a parameter that control learning rate in the online learning method. The value should be set between (0.5, 1.0] to guarantee asymptotic convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -8122533.54973646\n",
      "Perplexity:  3546.6198321572715\n"
     ]
    }
   ],
   "source": [
    "# Log Likelihood: Higher the better\n",
    "print(\"Log Likelihood: \", lda.score(doc_term_matrix))\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda.perplexity(doc_term_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of a LDA model can be measured using Log Likelihood and Perplexity metrics. A LDA mode with higher Log Likelihood is better than the model with lower Log Likelihood value. For  Perplexity metrix the model with loer value is consider as better one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17114"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return totla number of vocabularies in count_vectorizer\n",
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count vectorizer contains list of all words that were found within the text documents,w hich we selected using specifying max_df, min_df and removing the stop words with in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ap'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retun the word in the index position 1200\n",
    "count_vectorizer.get_feature_names()[1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.66666869e-02, 6.66667108e-02, 1.06666628e+00, ...,\n",
       "        6.66666906e-02, 6.66666696e-02, 6.66666667e-02],\n",
       "       [6.66666955e-02, 1.34321867e+01, 6.66666667e-02, ...,\n",
       "        6.66668042e-02, 6.66666757e-02, 6.66666821e-02],\n",
       "       [6.66668819e-02, 2.63734003e+02, 6.66667169e-02, ...,\n",
       "        6.66666846e-02, 6.66666909e-02, 6.66672558e-02],\n",
       "       ...,\n",
       "       [6.66667298e-02, 6.66666982e-02, 6.66666667e-02, ...,\n",
       "        6.66666667e-02, 6.66667770e-02, 6.66666742e-02],\n",
       "       [6.66666945e-02, 6.66667018e-02, 6.66666667e-02, ...,\n",
       "        6.66666667e-02, 6.66666725e-02, 9.06666605e+00],\n",
       "       [6.66666876e-02, 3.80882729e+01, 6.66667973e-02, ...,\n",
       "        6.66666667e-02, 5.62441492e-01, 6.66666667e-02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the probability distribution of words in the count_vectorizer corrsponding to each LDA component.\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here LDA model is consists of 15 components ie 15 topics and 17114 columns corresponding to  probability of each words in count vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 17114)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I printed all the top 20 words in each topics with larger probability. Number of words required in each topic is set using the variable top_number = 20. Using for loop at two level and extracted the individual words from count_vectorizer based on the indexnumber from components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for topic 0 are : \n",
      "['drive']['follow']['snapchat']['remove']['profile']['does']['hack']['problem']['delete']['car']['buy']['don']['know']['phone']['whatsapp']['mind']['people']['account']['facebook']['instagram']\n",
      "\n",
      "Top words for topic 1 are : \n",
      "['faster']['green']['ways']['way']['fast']['gain']['reduce']['review']['fat']['speed']['light']['war']['rid']['youtube']['hair']['movie']['does']['lose']['weight']['world']\n",
      "\n",
      "Top words for topic 2 are : \n",
      "['culture']['important']['market']['india']['know']['rupee']['government']['money']['black']['rs']['old']['going']['year']['1000']['500']['things']['notes']['indian']['day']['new']\n",
      "\n",
      "Top words for topic 3 are : \n",
      "['blood']['jee']['tv']['house']['tell']['power']['college']['date']['high']['different']['series']['game']['control']['2016']['guy']['video']['girls']['like']['girl']['know']\n",
      "\n",
      "Top words for topic 4 are : \n",
      "['life']['startup']['marketing']['differ']['idea']['united']['start']['states']['ways']['study']['sex']['work']['data']['earn']['business']['does']['online']['money']['good']['make']\n",
      "\n",
      "Top words for topic 5 are : \n",
      "['theory']['majors']['2016']['life']['presidential']['differences']['favorite']['purpose']['did']['looking']['right']['election']['win']['does']['math']['hillary']['clinton']['think']['donald']['trump']\n",
      "\n",
      "Top words for topic 6 are : \n",
      "['time']['tips']['mechanical']['process']['college']['engineer']['life']['career']['want']['student']['interview']['real']['year']['company']['improve']['good']['engineering']['english']['better']['job']\n",
      "\n",
      "Top words for topic 7 are : \n",
      "['story']['international']['advantages']['cat']['improvement']['experience']['child']['score']['war']['deal']['did']['interesting']['students']['usa']['does']['class']['countries']['years']['china']['president']\n",
      "\n",
      "Top words for topic 8 are : \n",
      "['provider']['games']['cost']['did']['solar']['major']['california']['created']['ca']['battle']['biggest']['compare']['place']['effects']['visit']['places']['pakistan']['energy']['best']['india']\n",
      "\n",
      "Top words for topic 9 are : \n",
      "['apps']['development']['support']['answers']['service']['windows']['answer']['web']['android']['people']['increase']['ask']['website']['app']['question']['use']['google']['questions']['best']['quora']\n",
      "\n",
      "Top words for topic 10 are : \n",
      "['happen']['look']['don']['relationship']['man']['time']['say']['think']['really']['person']['thing']['work']['long']['love']['feel']['mean']['did']['like']['people']['does']\n",
      "\n",
      "Top words for topic 11 are : \n",
      "['design']['watch']['improve']['prepare']['average']['hotel']['movie']['skills']['police']['java']['books']['learning']['movies']['book']['language']['programming']['start']['learn']['way']['best']\n",
      "\n",
      "Top words for topic 12 are : \n",
      "['matter']['air']['use']['size']['value']['people']['believe']['sentence']['sleep']['come']['god']['live']['human']['meaning']['life']['word']['like']['used']['country']['does']\n",
      "\n",
      "Top words for topic 13 are : \n",
      "['credit']['porn']['use']['using']['social']['mobile']['account']['laptop']['phone']['email']['travel']['password']['card']['possible']['science']['read']['number']['computer']['time']['difference']\n",
      "\n",
      "Top words for topic 14 are : \n",
      "['similar']['sell']['humans']['buy']['tv']['alcohol']['drug']['days']['center']['pregnant']['period']['test']['music']['song']['men']['women']['com']['water']['iphone']['examples']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a loop to show the top number of words for each topic\n",
    "word_list = []\n",
    "probability_list = []\n",
    "\n",
    "top_number = 20\n",
    "count = 0\n",
    "for probability_number in lda.components_:\n",
    "    text_message = f\"Top words for topic {count} are : \"\n",
    "    print(text_message)    \n",
    "    for number in probability_number.argsort()[-top_number:]:\n",
    "        print([count_vectorizer.get_feature_names()[number]], end= \"\")\n",
    "    print(\"\\n\")  \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15 topic with top 20 words related to each topic is printed above. Topic 0 can be considered as Social Media becuase top 20 words listed in it is manly related to questions related to social media. In the same way analysig the remaining topic we can inference a new topic based on most corelated words in the list. Even though we can observe that there is many words in each topic with no corelation between each other. It is also visible that some topics are highly related to each other based on the listed words. \n",
    "\n",
    "These problems are hoping to solve using lowering the components_ value and adjusting max_df and min_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the probability of each text file belonging to a particular topic\n",
    "textfile_topics = lda.transform(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200001, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfile_topics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains list of the 15 topics for all questions, so there are 200001 text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Topic number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>528339</th>\n",
       "      <td>How do I hack a wifi?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161450</th>\n",
       "      <td>Wwe is real fight?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699472</th>\n",
       "      <td>What is written in vedas?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736752</th>\n",
       "      <td>Why don't women propose to men in India?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772144</th>\n",
       "      <td>Which car should I buy for my parents in India?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329727</th>\n",
       "      <td>Would there be trans people if society had no ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467123</th>\n",
       "      <td>What is a data scientist?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565569</th>\n",
       "      <td>I recently lost my phone. How can I get it back?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450954</th>\n",
       "      <td>How do I use anonymous.com?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682524</th>\n",
       "      <td>What are the best Bollywood movies of 2016 so ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251368</th>\n",
       "      <td>How can learn English?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644404</th>\n",
       "      <td>What is the best strategy to increase engageme...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765818</th>\n",
       "      <td>Why can't men wear tights?</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786053</th>\n",
       "      <td>CSIM, Matlab, Java sim which would be best for...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348011</th>\n",
       "      <td>What is like to study international relations?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231021</th>\n",
       "      <td>Which is the best phone below 15000?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797148</th>\n",
       "      <td>What will the afterlife be like?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322078</th>\n",
       "      <td>How safe is Georgia?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697576</th>\n",
       "      <td>What is ink made from? How is it made?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50270</th>\n",
       "      <td>What are the most efficient methods for me to ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165330</th>\n",
       "      <td>Do engineering classes depend on physics and c...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362543</th>\n",
       "      <td>Are dark matter and dark energy: energy?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513003</th>\n",
       "      <td>Are structural health monitoring researches sa...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80162</th>\n",
       "      <td>Can I use open source software for commercial ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744948</th>\n",
       "      <td>Why can't I buy with my gift card balance on A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140523</th>\n",
       "      <td>Are there any languages that are still spoken,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749240</th>\n",
       "      <td>How Subsea Wells are drilled?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10093</th>\n",
       "      <td>How do you see PM2.5?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628946</th>\n",
       "      <td>What is it like to regret having children?</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700965</th>\n",
       "      <td>What do you think about the BJP government not...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477190</th>\n",
       "      <td>What are good books written in Tamil that have...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596301</th>\n",
       "      <td>How immediately come frog in rainy day?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622972</th>\n",
       "      <td>Why isn't Quora listed in Klout?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75637</th>\n",
       "      <td>Do you really think what ever happens is as pe...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307044</th>\n",
       "      <td>What is the english translation for the word i...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334078</th>\n",
       "      <td>How does one deal with a bully at work?</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550572</th>\n",
       "      <td>What is genetic drift? What are some types?</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210962</th>\n",
       "      <td>Which hotels in ernakulam allow unmarried coup...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373899</th>\n",
       "      <td>Is Bitcoin mining still profitable in 2016?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587383</th>\n",
       "      <td>What is the most popular board game that is no...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506388</th>\n",
       "      <td>What is the single best excercise for your abs?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120229</th>\n",
       "      <td>What time does USPS usually deliver?</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78277</th>\n",
       "      <td>Bitcoin in India: Where can I buy bitcoins in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472705</th>\n",
       "      <td>Wouldn't ISPs block forum sites without net ne...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250435</th>\n",
       "      <td>Why did Zeus trick Hades ?And he gave him the ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264339</th>\n",
       "      <td>How can I become a professional listener?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669794</th>\n",
       "      <td>How big a problem is people mischievously edit...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407767</th>\n",
       "      <td>Why do people bully others?</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782464</th>\n",
       "      <td>How should we define an engaged user for Google+?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378393</th>\n",
       "      <td>What are the best colleges for studying econom...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136275</th>\n",
       "      <td>Where can I find public or free real-time or s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236428</th>\n",
       "      <td>How do I learn machine learning?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474798</th>\n",
       "      <td>How can I learn to speak English fluently?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765494</th>\n",
       "      <td>How will it be after death? Where does the sou...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627277</th>\n",
       "      <td>What are some differences between Latin Americ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256607</th>\n",
       "      <td>What is an inclined plane? What are examples o...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300740</th>\n",
       "      <td>How can I prove that a negative number multipl...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531674</th>\n",
       "      <td>How do I learn English step by step?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139362</th>\n",
       "      <td>In what ways are you privileged and in what wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702490</th>\n",
       "      <td>Is time travel possible? If yes how</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  Topic number\n",
       "528339                              How do I hack a wifi?            13\n",
       "161450                                 Wwe is real fight?             6\n",
       "699472                          What is written in vedas?             6\n",
       "736752           Why don't women propose to men in India?             3\n",
       "772144    Which car should I buy for my parents in India?             0\n",
       "329727  Would there be trans people if society had no ...             5\n",
       "467123                          What is a data scientist?             4\n",
       "565569   I recently lost my phone. How can I get it back?            13\n",
       "450954                        How do I use anonymous.com?             9\n",
       "682524  What are the best Bollywood movies of 2016 so ...            11\n",
       "251368                             How can learn English?            11\n",
       "644404  What is the best strategy to increase engageme...             9\n",
       "765818                         Why can't men wear tights?            14\n",
       "786053  CSIM, Matlab, Java sim which would be best for...             5\n",
       "348011     What is like to study international relations?             7\n",
       "231021               Which is the best phone below 15000?            11\n",
       "797148                   What will the afterlife be like?             7\n",
       "322078                               How safe is Georgia?             0\n",
       "697576             What is ink made from? How is it made?            13\n",
       "50270   What are the most efficient methods for me to ...            11\n",
       "165330  Do engineering classes depend on physics and c...            11\n",
       "362543           Are dark matter and dark energy: energy?             8\n",
       "513003  Are structural health monitoring researches sa...             5\n",
       "80162   Can I use open source software for commercial ...             9\n",
       "744948  Why can't I buy with my gift card balance on A...             4\n",
       "140523  Are there any languages that are still spoken,...            12\n",
       "749240                      How Subsea Wells are drilled?            13\n",
       "10093                               How do you see PM2.5?             0\n",
       "628946         What is it like to regret having children?            10\n",
       "700965  What do you think about the BJP government not...             2\n",
       "...                                                   ...           ...\n",
       "477190  What are good books written in Tamil that have...            11\n",
       "596301            How immediately come frog in rainy day?             9\n",
       "622972                   Why isn't Quora listed in Klout?             9\n",
       "75637   Do you really think what ever happens is as pe...             7\n",
       "307044  What is the english translation for the word i...             6\n",
       "334078            How does one deal with a bully at work?            10\n",
       "550572        What is genetic drift? What are some types?            14\n",
       "210962  Which hotels in ernakulam allow unmarried coup...            11\n",
       "373899        Is Bitcoin mining still profitable in 2016?             4\n",
       "587383  What is the most popular board game that is no...             3\n",
       "506388    What is the single best excercise for your abs?             1\n",
       "120229               What time does USPS usually deliver?            10\n",
       "78277   Bitcoin in India: Where can I buy bitcoins in ...             0\n",
       "472705  Wouldn't ISPs block forum sites without net ne...            13\n",
       "250435  Why did Zeus trick Hades ?And he gave him the ...            10\n",
       "264339          How can I become a professional listener?            11\n",
       "669794  How big a problem is people mischievously edit...             9\n",
       "407767                        Why do people bully others?            12\n",
       "782464  How should we define an engaged user for Google+?             0\n",
       "378393  What are the best colleges for studying econom...             6\n",
       "136275  Where can I find public or free real-time or s...             4\n",
       "236428                   How do I learn machine learning?            11\n",
       "474798         How can I learn to speak English fluently?             6\n",
       "765494  How will it be after death? Where does the sou...            12\n",
       "627277  What are some differences between Latin Americ...            10\n",
       "256607  What is an inclined plane? What are examples o...            14\n",
       "300740  How can I prove that a negative number multipl...            13\n",
       "531674               How do I learn English step by step?            11\n",
       "139362  In what ways are you privileged and in what wa...             4\n",
       "702490                Is time travel possible? If yes how            13\n",
       "\n",
       "[200001 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm using a loop to find the highest topic number that each document belongs to\n",
    "# then assigning that number to the data frame.\n",
    "# the topic number will extracted using argmax() function and append with topic_list array.\n",
    "# The new array will inserted in to the data frame as a new column name Topic number\n",
    "\n",
    "topic_list = []\n",
    "# Textfile_topics is a list of arrays containing \n",
    "# all index positions of words for each textfile\n",
    "for popular_index_pos in textfile_topics:\n",
    "    # Get the max index position in each array\n",
    "    # and add to the topic_list list\n",
    "    topic_list.append(popular_index_pos.argmax())\n",
    "\n",
    "# Add a new column to the dataframe\n",
    "dataframe[\"Topic number\"] = topic_list\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the above table, it is clear that the topic modelling corresponding to the questions in the data frame is not much accurate.\n",
    "\n",
    "It is clear that we  need a bettere model with higher accuracy. Majority of topic number assigned to the questions in the data frame is not correct one. \n",
    "\n",
    "We can create a new better model by adjusting the max_df and min_df values and choosing best parameter values for components and learning decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch for the best LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use GridSearch to find out best LDA model with optimized parameter values. We can set custem search patterns with range of values for each LDA model parameters. n_components, learning_decay, learning_offset, and max_iter are the major possible search parameters we can use  with our GridSearch. \n",
    "\n",
    "The grid search constructs multiple LDA models for all possible combinations of param values in the param_grid dict. Here for our model we are only using n_components and learning_decay parameters only for our search amd model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_components': [10, 15, 20], 'learning_decay': [0.5, 0.7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define Search Param\n",
    "search_params = {'n_components': [10, 15, 20], 'learning_decay': [.5, .7]}\n",
    "\n",
    "# Init the Model\n",
    "lda_comparison = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "lda_comparison = GridSearchCV(lda_comparison, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "lda_comparison.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.5, 'n_components': 10}\n",
      "Best Log Likelihood Score:  -2823614.4162483294\n",
      "Model Perplexity:  3469.486589798985\n"
     ]
    }
   ],
   "source": [
    "# Best Model which gave highest score \n",
    "best_lda_model = lda_comparison.best_estimator_\n",
    "\n",
    "# Model Parameters is used to store a list of parameter settings dicts for all the parameter candidates\n",
    "print(\"Best Model's Params: \", lda_comparison.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", lda_comparison.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(doc_term_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model Performance Scores analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the grid search,  from the output it is clear that, learning_decay': 0.5, and 'n_components': 10 are the optimized parameter to create a best fit model.\n",
    "\n",
    "For the suggested model the Log Likelihood Score = -2823614.4162483294 and for the previous model the og Likelihood Score = -8122533.54973646.\n",
    "\n",
    "The Log Likelihood score of the new suggested model is much higher than previous model.\n",
    "\n",
    "In the same way the Model Perplexity of the first model with n_components = 15 is 3546.6198321572715 and for our new GridSearch suggested model the Perplexity score is 3469.486589798985 which is smaller than the first model.\n",
    "\n",
    "Hence we can conclude that constructiong a new model with learning_decay': 0.5, n_components': 10 and random_state= None can deliver better out put.\n",
    "\n",
    "So we need to construct a new model with n_components': 10 and learning_decay': 0.5 \n",
    "\n",
    "ie a new model to suggest 10 topic categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New LDA Model with new parameters - Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200001x27010 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 988045 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise an instance of the count vectorizer\n",
    "count_vectorizer1 = CountVectorizer(max_df=0.90, min_df=2, stop_words=\"english\")\n",
    "# fit and then transforms data into a numerical vector\n",
    "doc_term_matrix1 = count_vectorizer1.fit_transform(dataframe[\"question\"])\n",
    "# print the new doc_term_matrix1\n",
    "doc_term_matrix1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create a new doc_term_matrix1 by setting max_df=0.90 and min_df=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise an instance of the LDA with GridSearch suggested parameters\n",
    "lda2 = LatentDirichletAllocation(n_components=10,learning_decay=0.5,random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.5,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with new doc_term_matrix1\n",
    "lda2.fit(doc_term_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -8516714.2002367\n",
      "Perplexity:  4318.106941042106\n"
     ]
    }
   ],
   "source": [
    "# Log Likelihood Score\n",
    "print(\"Log Likelihood: \", lda2.score(doc_term_matrix1))\n",
    "# Perplexity\n",
    "print(\"Perplexity: \", lda2.perplexity(doc_term_matrix1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Log Likelihood = -8516714.2002367 and for the first model Log Likelihood = -8122533.54973646. so Log Likelihood of our new model is smaller than the previous one.\n",
    "\n",
    "For the new model Perplexity: 4318.106941042106 and for the previous one Perplexity: 3546.6198321572715. The Perplexity of the new model is larger than t he first model.\n",
    "\n",
    "Smaller Log Likelihood value and larger Perplexity of our new model suggest that this model is Not better than the first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A New Model with suggested gridsearch parammeters - Model -3\n",
    "\n",
    "n_components=10,\n",
    "learning_decay=0.5\n",
    "\n",
    "and max_df = 0.70 and min_df = 4. ( ie first model values  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200001x17114 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 964821 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise an instance of the count vectorizer\n",
    "count_vectorizer1 = CountVectorizer(max_df=0.70, min_df=4, stop_words=\"english\")\n",
    "# fit and then transforms data into a numerical vector\n",
    "doc_term_matrix1 = count_vectorizer1.fit_transform(dataframe[\"question\"])\n",
    "# print the new doc_term_matrix1\n",
    "doc_term_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise an instance of the LDA with GridSearch suggested parameters\n",
    "lda2 = LatentDirichletAllocation(n_components=10,learning_decay=0.5,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.5,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=1, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with new doc_term_matrix1\n",
    "lda2.fit(doc_term_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -8146711.012216317\n",
      "Perplexity:  3633.9670531592847\n"
     ]
    }
   ],
   "source": [
    "# Log Likelihood Score\n",
    "print(\"Log Likelihood: \", lda2.score(doc_term_matrix1))\n",
    "# Perplexity\n",
    "print(\"Perplexity: \", lda2.perplexity(doc_term_matrix1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Log Likelihood = -8146711.012216317 and for the first model Log Likelihood = -8122533.54973646. so Log Likelihood of our new model is slightly smaller than the previous one.\n",
    "\n",
    "For the new model Perplexity:  3633.9670531592847 and for the previous one Perplexity: 3546.6198321572715. The Perplexity of the new model is larger than the first model. \n",
    "\n",
    "\n",
    "So slightly Smaller Log Likelihood value and larger Perplexity of our new model suggest that the model is Not better than the first model but almost equal to the first model in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following the all previously explaned step to create the Topic Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17114"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return totla number of vocabularies in count_vectorizer\n",
    "len(count_vectorizer1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ap'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retun the word in the index position 1200\n",
    "count_vectorizer1.get_feature_names()[1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00005944e-01, 1.00004095e-01, 1.00004870e-01, ...,\n",
       "        1.00002580e-01, 1.00001692e-01, 1.00000000e-01],\n",
       "       [1.00009717e-01, 1.16375945e-01, 1.00000000e-01, ...,\n",
       "        1.00006453e-01, 1.00000800e-01, 1.00007799e-01],\n",
       "       [1.00021518e-01, 1.52306387e+02, 1.00016488e-01, ...,\n",
       "        1.00006784e-01, 1.00002340e-01, 1.00124851e-01],\n",
       "       ...,\n",
       "       [3.70547144e+01, 1.00004732e-01, 1.00000000e-01, ...,\n",
       "        1.00000001e-01, 1.00000848e-01, 1.00000000e-01],\n",
       "       [1.45216835e-01, 4.27248340e-01, 1.00000000e-01, ...,\n",
       "        8.09994912e+00, 1.00007402e-01, 1.00000001e-01],\n",
       "       [1.00004585e-01, 1.00536290e-01, 1.00000000e-01, ...,\n",
       "        1.00000348e-01, 1.00000308e-01, 9.09985370e+00]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the probability distribution of words in the count_vectorizer corrsponding to each LDA component.\n",
    "lda2.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 17114)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here LDA model is consists of 10 components ie 10 topics and 17114 columns corresponding to probability of each words in count vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the index positions of the first topic into an array\n",
    "first_topic = lda2.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5523,  3001,  2041, ...,   601, 12398, 11341])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return sorted index position of vocabulary\n",
    "first_topic.argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sorted index positions of the least to greatest values of the probability of words using the argsort() command. Otherwise we would have a random list of index positions based on the count vectorizer.\n",
    "\n",
    "The outputted list represents the entire index positions of all probabilities of words for the entire vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17114, numpy.ndarray)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_topic.argsort()), type(first_topic.argsort())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argsort array is the same size as the count vectorizer since is represents a list of probabilities for all words that exist in the vocabulary of words from the text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10649,  9870, 11229, 11395, 12373,  8656, 11474,  8149,  7941,\n",
       "        4888,  4916,  5816,   601, 12398, 11341])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_topic.argsort()[-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the highest probabilities of words for the first topic by going to the end of the array and chooing the least number of numbers. For example, to view the top 15 highest probability of words for the first topic, going from 15th to 1st,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maroon\n"
     ]
    }
   ],
   "source": [
    "# retun the word in the index position 9493\n",
    "print(count_vectorizer1.get_feature_names()[9493])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquisitions\n"
     ]
    }
   ],
   "source": [
    "# retun the word in the index position 646\n",
    "print(count_vectorizer1.get_feature_names()[646])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "showing the words in the first topic using a loop.\n",
    "Here using a function, first to take in the x and y axis data and to then generate a bar chart of the most common words that belog to the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_chart(words, count, chart_title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    d = pd.DataFrame({\"Words\": word_list, \"Count\": probability_list})\n",
    "    # Sort the dataframe by largest count\n",
    "    d = d.sort_values(by=[\"Count\"], ascending=False)\n",
    "    ax = d.plot.bar(y = \"Count\", \n",
    "                    x=\"Words\", \n",
    "                    title= chart_title, \n",
    "                    figsize=(15, 10), \n",
    "                    legend=True, \n",
    "                    fontsize=12, \n",
    "                    rot=1)\n",
    "    ax.set_xlabel(\"Frequent words\", fontsize=12)\n",
    "    ax.set_ylabel(\"Word count\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number\n",
      "mind\n",
      "password\n",
      "person\n",
      "question\n",
      "know\n",
      "phone\n",
      "iphone\n",
      "instagram\n",
      "does\n",
      "don\n",
      "facebook\n",
      "account\n",
      "quora\n",
      "people\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_list = []\n",
    "probability_list = []\n",
    "\n",
    "for index in first_topic.argsort()[-15:]:\n",
    "    frequent_word = count_vectorizer1.get_feature_names()[index]\n",
    "    print(frequent_word, sep=\" \")\n",
    "    word_list.append(frequent_word)\n",
    "    probability_list.append(index)\n",
    "    \n",
    "show_chart(word_list, probability_list, \"Word probability for first topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for topic 0 are : \n",
      "['use']['human']['email']['exist']['whatsapp']['number']['mind']['password']['person']['question']['know']['phone']['iphone']['instagram']['does']['don']['facebook']['account']['quora']['people']\n",
      "\n",
      "Top words for topic 1 are : \n",
      "['time']['fat']['youtube']['light']['war']['hair']['did']['friend']['earth']['way']['movie']['lose']['weight']['feel']['love']['best']['like']['mean']['world']['does']\n",
      "\n",
      "Top words for topic 2 are : \n",
      "['online']['earn']['black']['important']['government']['language']['year']['rs']['going']['india']['indian']['know']['things']['1000']['500']['notes']['day']['new']['make']['money']\n",
      "\n",
      "Top words for topic 3 are : \n",
      "['power']['difference']['card']['series']['guy']['control']['school']['game']['college']['know']['tv']['girls']['high']['long']['water']['2016']['examples']['girl']['does']['like']\n",
      "\n",
      "Top words for topic 4 are : \n",
      "['management']['period']['relationship']['days']['data']['united']['states']['girlfriend']['online']['people']['make']['bad']['like']['study']['business']['sex']['work']['difference']['does']['good']\n",
      "\n",
      "Top words for topic 5 are : \n",
      "['skills']['used']['god']['men']['election']['right']['favorite']['stop']['women']['president']['math']['hillary']['win']['clinton']['does']['did']['people']['donald']['think']['trump']\n",
      "\n",
      "Top words for topic 6 are : \n",
      "['company']['years']['tips']['live']['process']['travel']['home']['possible']['want']['interview']['real']['good']['year']['old']['improve']['job']['better']['english']['time']['life']\n",
      "\n",
      "Top words for topic 7 are : \n",
      "['indian']['time']['interesting']['cat']['country']['university']['years']['usa']['class']['experience']['countries']['india']['students']['exam']['china']['prepare']['movies']['does']['did']['engineering']\n",
      "\n",
      "Top words for topic 8 are : \n",
      "['compare']['biggest']['universe']['worst']['meaning']['food']['effects']['hotel']['police']['visit']['places']['did']['pakistan']['place']['eat']['safe']['energy']['thing']['best']['india']\n",
      "\n",
      "Top words for topic 9 are : \n",
      "['online']['read']['science']['app']['learning']['ask']['free']['computer']['google']['website']['good']['book']['books']['questions']['use']['start']['quora']['learn']['way']['best']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "probability_list = []\n",
    "\n",
    "top_number = 20\n",
    "count = 0\n",
    "for probability_number in lda2.components_:\n",
    "    text_message = f\"Top words for topic {count} are : \"\n",
    "    print(text_message)    \n",
    "    for number in probability_number.argsort()[-top_number:]:\n",
    "        print([count_vectorizer1.get_feature_names()[number]], end= \"\")\n",
    "    print(\"\\n\")  \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return  the probability of each particular questions file belonging to a particular topic\n",
    "textfile_topics = lda2.transform(doc_term_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69999891, 0.03333333, 0.03333333, ..., 0.03333333, 0.03333333,\n",
       "        0.03333442],\n",
       "       [0.025     , 0.02500002, 0.02500284, ..., 0.02500048, 0.02500233,\n",
       "        0.025     ],\n",
       "       [0.03333333, 0.03333333, 0.0333361 , ..., 0.03333691, 0.03333333,\n",
       "        0.03334843],\n",
       "       ...,\n",
       "       [0.02      , 0.02000009, 0.54067461, ..., 0.02      , 0.02      ,\n",
       "        0.02001095],\n",
       "       [0.02500192, 0.02500656, 0.52484821, ..., 0.02500001, 0.27512723,\n",
       "        0.02500861],\n",
       "       [0.02000122, 0.02000147, 0.02000024, ..., 0.02000042, 0.02000064,\n",
       "        0.02000035]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfile_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = []  # declaring a empty array\n",
    "# Textfile_topics is a list of arrays containing \n",
    "# all index positions of words for each textfile\n",
    "for popular_index_pos in textfile_topics:\n",
    "    # Get the max index position in each array\n",
    "    # and add to the topic_list list\n",
    "    topic_list.append(popular_index_pos.argmax())\n",
    "\n",
    "# Add a new column to the dataframe\n",
    "dataframe[\"Topic number\"] = topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Topic number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>528339</th>\n",
       "      <td>How do I hack a wifi?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161450</th>\n",
       "      <td>Wwe is real fight?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699472</th>\n",
       "      <td>What is written in vedas?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736752</th>\n",
       "      <td>Why don't women propose to men in India?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772144</th>\n",
       "      <td>Which car should I buy for my parents in India?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329727</th>\n",
       "      <td>Would there be trans people if society had no ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467123</th>\n",
       "      <td>What is a data scientist?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565569</th>\n",
       "      <td>I recently lost my phone. How can I get it back?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450954</th>\n",
       "      <td>How do I use anonymous.com?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682524</th>\n",
       "      <td>What are the best Bollywood movies of 2016 so ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251368</th>\n",
       "      <td>How can learn English?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644404</th>\n",
       "      <td>What is the best strategy to increase engageme...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765818</th>\n",
       "      <td>Why can't men wear tights?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786053</th>\n",
       "      <td>CSIM, Matlab, Java sim which would be best for...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348011</th>\n",
       "      <td>What is like to study international relations?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231021</th>\n",
       "      <td>Which is the best phone below 15000?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797148</th>\n",
       "      <td>What will the afterlife be like?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322078</th>\n",
       "      <td>How safe is Georgia?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697576</th>\n",
       "      <td>What is ink made from? How is it made?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50270</th>\n",
       "      <td>What are the most efficient methods for me to ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165330</th>\n",
       "      <td>Do engineering classes depend on physics and c...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362543</th>\n",
       "      <td>Are dark matter and dark energy: energy?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513003</th>\n",
       "      <td>Are structural health monitoring researches sa...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80162</th>\n",
       "      <td>Can I use open source software for commercial ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744948</th>\n",
       "      <td>Why can't I buy with my gift card balance on A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140523</th>\n",
       "      <td>Are there any languages that are still spoken,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749240</th>\n",
       "      <td>How Subsea Wells are drilled?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10093</th>\n",
       "      <td>How do you see PM2.5?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628946</th>\n",
       "      <td>What is it like to regret having children?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700965</th>\n",
       "      <td>What do you think about the BJP government not...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477190</th>\n",
       "      <td>What are good books written in Tamil that have...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596301</th>\n",
       "      <td>How immediately come frog in rainy day?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622972</th>\n",
       "      <td>Why isn't Quora listed in Klout?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75637</th>\n",
       "      <td>Do you really think what ever happens is as pe...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307044</th>\n",
       "      <td>What is the english translation for the word i...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334078</th>\n",
       "      <td>How does one deal with a bully at work?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550572</th>\n",
       "      <td>What is genetic drift? What are some types?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210962</th>\n",
       "      <td>Which hotels in ernakulam allow unmarried coup...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373899</th>\n",
       "      <td>Is Bitcoin mining still profitable in 2016?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587383</th>\n",
       "      <td>What is the most popular board game that is no...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506388</th>\n",
       "      <td>What is the single best excercise for your abs?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120229</th>\n",
       "      <td>What time does USPS usually deliver?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78277</th>\n",
       "      <td>Bitcoin in India: Where can I buy bitcoins in ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472705</th>\n",
       "      <td>Wouldn't ISPs block forum sites without net ne...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250435</th>\n",
       "      <td>Why did Zeus trick Hades ?And he gave him the ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264339</th>\n",
       "      <td>How can I become a professional listener?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669794</th>\n",
       "      <td>How big a problem is people mischievously edit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407767</th>\n",
       "      <td>Why do people bully others?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782464</th>\n",
       "      <td>How should we define an engaged user for Google+?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378393</th>\n",
       "      <td>What are the best colleges for studying econom...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136275</th>\n",
       "      <td>Where can I find public or free real-time or s...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236428</th>\n",
       "      <td>How do I learn machine learning?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474798</th>\n",
       "      <td>How can I learn to speak English fluently?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765494</th>\n",
       "      <td>How will it be after death? Where does the sou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627277</th>\n",
       "      <td>What are some differences between Latin Americ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256607</th>\n",
       "      <td>What is an inclined plane? What are examples o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300740</th>\n",
       "      <td>How can I prove that a negative number multipl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531674</th>\n",
       "      <td>How do I learn English step by step?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139362</th>\n",
       "      <td>In what ways are you privileged and in what wa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702490</th>\n",
       "      <td>Is time travel possible? If yes how</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  Topic number\n",
       "528339                              How do I hack a wifi?             0\n",
       "161450                                 Wwe is real fight?             6\n",
       "699472                          What is written in vedas?             6\n",
       "736752           Why don't women propose to men in India?             5\n",
       "772144    Which car should I buy for my parents in India?             8\n",
       "329727  Would there be trans people if society had no ...             0\n",
       "467123                          What is a data scientist?             4\n",
       "565569   I recently lost my phone. How can I get it back?             3\n",
       "450954                        How do I use anonymous.com?             9\n",
       "682524  What are the best Bollywood movies of 2016 so ...             1\n",
       "251368                             How can learn English?             6\n",
       "644404  What is the best strategy to increase engageme...             9\n",
       "765818                         Why can't men wear tights?             5\n",
       "786053  CSIM, Matlab, Java sim which would be best for...             9\n",
       "348011     What is like to study international relations?             7\n",
       "231021               Which is the best phone below 15000?             0\n",
       "797148                   What will the afterlife be like?             7\n",
       "322078                               How safe is Georgia?             0\n",
       "697576             What is ink made from? How is it made?             0\n",
       "50270   What are the most efficient methods for me to ...             6\n",
       "165330  Do engineering classes depend on physics and c...             9\n",
       "362543           Are dark matter and dark energy: energy?             8\n",
       "513003  Are structural health monitoring researches sa...             7\n",
       "80162   Can I use open source software for commercial ...             9\n",
       "744948  Why can't I buy with my gift card balance on A...             4\n",
       "140523  Are there any languages that are still spoken,...             2\n",
       "749240                      How Subsea Wells are drilled?             3\n",
       "10093                               How do you see PM2.5?             0\n",
       "628946         What is it like to regret having children?             4\n",
       "700965  What do you think about the BJP government not...             2\n",
       "...                                                   ...           ...\n",
       "477190  What are good books written in Tamil that have...             6\n",
       "596301            How immediately come frog in rainy day?             2\n",
       "622972                   Why isn't Quora listed in Klout?             9\n",
       "75637   Do you really think what ever happens is as pe...             7\n",
       "307044  What is the english translation for the word i...             6\n",
       "334078            How does one deal with a bully at work?             4\n",
       "550572        What is genetic drift? What are some types?             7\n",
       "210962  Which hotels in ernakulam allow unmarried coup...             8\n",
       "373899        Is Bitcoin mining still profitable in 2016?             2\n",
       "587383  What is the most popular board game that is no...             3\n",
       "506388    What is the single best excercise for your abs?             1\n",
       "120229               What time does USPS usually deliver?             4\n",
       "78277   Bitcoin in India: Where can I buy bitcoins in ...             8\n",
       "472705  Wouldn't ISPs block forum sites without net ne...             9\n",
       "250435  Why did Zeus trick Hades ?And he gave him the ...             8\n",
       "264339          How can I become a professional listener?             0\n",
       "669794  How big a problem is people mischievously edit...             4\n",
       "407767                        Why do people bully others?             8\n",
       "782464  How should we define an engaged user for Google+?             0\n",
       "378393  What are the best colleges for studying econom...             7\n",
       "136275  Where can I find public or free real-time or s...             6\n",
       "236428                   How do I learn machine learning?             9\n",
       "474798         How can I learn to speak English fluently?             6\n",
       "765494  How will it be after death? Where does the sou...             1\n",
       "627277  What are some differences between Latin Americ...             4\n",
       "256607  What is an inclined plane? What are examples o...             0\n",
       "300740  How can I prove that a negative number multipl...             5\n",
       "531674               How do I learn English step by step?             2\n",
       "139362  In what ways are you privileged and in what wa...             2\n",
       "702490                Is time travel possible? If yes how             6\n",
       "\n",
       "[200001 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can examine each topic and assign matching descrptions for each topic number. I'll create a list of topic number with relevant text and then match the topic number to the relevant topic text using the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = {0: \"Technology\", \n",
    "              1: \"Life Style\", \n",
    "              2: \"Business\", \n",
    "              3: \"Activities\", \n",
    "              4: \"Relationships\", \n",
    "              5: \"Politics\", \n",
    "              6: \"Work & Careers\", \n",
    "              7: \"Education\", \n",
    "              8: \"Travel\", \n",
    "              9: \"Learning\", \n",
    "              }\n",
    "\n",
    "topic_no_to_topic = dataframe[\"Topic number\"].map(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Topic number</th>\n",
       "      <th>Topic desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>528339</th>\n",
       "      <td>How do I hack a wifi?</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161450</th>\n",
       "      <td>Wwe is real fight?</td>\n",
       "      <td>6</td>\n",
       "      <td>Work &amp; Careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699472</th>\n",
       "      <td>What is written in vedas?</td>\n",
       "      <td>6</td>\n",
       "      <td>Work &amp; Careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736752</th>\n",
       "      <td>Why don't women propose to men in India?</td>\n",
       "      <td>5</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772144</th>\n",
       "      <td>Which car should I buy for my parents in India?</td>\n",
       "      <td>8</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329727</th>\n",
       "      <td>Would there be trans people if society had no ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467123</th>\n",
       "      <td>What is a data scientist?</td>\n",
       "      <td>4</td>\n",
       "      <td>Relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565569</th>\n",
       "      <td>I recently lost my phone. How can I get it back?</td>\n",
       "      <td>3</td>\n",
       "      <td>Activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450954</th>\n",
       "      <td>How do I use anonymous.com?</td>\n",
       "      <td>9</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682524</th>\n",
       "      <td>What are the best Bollywood movies of 2016 so ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251368</th>\n",
       "      <td>How can learn English?</td>\n",
       "      <td>6</td>\n",
       "      <td>Work &amp; Careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644404</th>\n",
       "      <td>What is the best strategy to increase engageme...</td>\n",
       "      <td>9</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765818</th>\n",
       "      <td>Why can't men wear tights?</td>\n",
       "      <td>5</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786053</th>\n",
       "      <td>CSIM, Matlab, Java sim which would be best for...</td>\n",
       "      <td>9</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348011</th>\n",
       "      <td>What is like to study international relations?</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231021</th>\n",
       "      <td>Which is the best phone below 15000?</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797148</th>\n",
       "      <td>What will the afterlife be like?</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322078</th>\n",
       "      <td>How safe is Georgia?</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697576</th>\n",
       "      <td>What is ink made from? How is it made?</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50270</th>\n",
       "      <td>What are the most efficient methods for me to ...</td>\n",
       "      <td>6</td>\n",
       "      <td>Work &amp; Careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165330</th>\n",
       "      <td>Do engineering classes depend on physics and c...</td>\n",
       "      <td>9</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362543</th>\n",
       "      <td>Are dark matter and dark energy: energy?</td>\n",
       "      <td>8</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513003</th>\n",
       "      <td>Are structural health monitoring researches sa...</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80162</th>\n",
       "      <td>Can I use open source software for commercial ...</td>\n",
       "      <td>9</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744948</th>\n",
       "      <td>Why can't I buy with my gift card balance on A...</td>\n",
       "      <td>4</td>\n",
       "      <td>Relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140523</th>\n",
       "      <td>Are there any languages that are still spoken,...</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749240</th>\n",
       "      <td>How Subsea Wells are drilled?</td>\n",
       "      <td>3</td>\n",
       "      <td>Activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10093</th>\n",
       "      <td>How do you see PM2.5?</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628946</th>\n",
       "      <td>What is it like to regret having children?</td>\n",
       "      <td>4</td>\n",
       "      <td>Relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700965</th>\n",
       "      <td>What do you think about the BJP government not...</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477190</th>\n",
       "      <td>What are good books written in Tamil that have...</td>\n",
       "      <td>6</td>\n",
       "      <td>Work &amp; Careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596301</th>\n",
       "      <td>How immediately come frog in rainy day?</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622972</th>\n",
       "      <td>Why isn't Quora listed in Klout?</td>\n",
       "      <td>9</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75637</th>\n",
       "      <td>Do you really think what ever happens is as pe...</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307044</th>\n",
       "      <td>What is the english translation for the word i...</td>\n",
       "      <td>6</td>\n",
       "      <td>Work &amp; Careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334078</th>\n",
       "      <td>How does one deal with a bully at work?</td>\n",
       "      <td>4</td>\n",
       "      <td>Relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550572</th>\n",
       "      <td>What is genetic drift? What are some types?</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210962</th>\n",
       "      <td>Which hotels in ernakulam allow unmarried coup...</td>\n",
       "      <td>8</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373899</th>\n",
       "      <td>Is Bitcoin mining still profitable in 2016?</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587383</th>\n",
       "      <td>What is the most popular board game that is no...</td>\n",
       "      <td>3</td>\n",
       "      <td>Activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506388</th>\n",
       "      <td>What is the single best excercise for your abs?</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120229</th>\n",
       "      <td>What time does USPS usually deliver?</td>\n",
       "      <td>4</td>\n",
       "      <td>Relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78277</th>\n",
       "      <td>Bitcoin in India: Where can I buy bitcoins in ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472705</th>\n",
       "      <td>Wouldn't ISPs block forum sites without net ne...</td>\n",
       "      <td>9</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250435</th>\n",
       "      <td>Why did Zeus trick Hades ?And he gave him the ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264339</th>\n",
       "      <td>How can I become a professional listener?</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669794</th>\n",
       "      <td>How big a problem is people mischievously edit...</td>\n",
       "      <td>4</td>\n",
       "      <td>Relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407767</th>\n",
       "      <td>Why do people bully others?</td>\n",
       "      <td>8</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782464</th>\n",
       "      <td>How should we define an engaged user for Google+?</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378393</th>\n",
       "      <td>What are the best colleges for studying econom...</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136275</th>\n",
       "      <td>Where can I find public or free real-time or s...</td>\n",
       "      <td>6</td>\n",
       "      <td>Work &amp; Careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236428</th>\n",
       "      <td>How do I learn machine learning?</td>\n",
       "      <td>9</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474798</th>\n",
       "      <td>How can I learn to speak English fluently?</td>\n",
       "      <td>6</td>\n",
       "      <td>Work &amp; Careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765494</th>\n",
       "      <td>How will it be after death? Where does the sou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627277</th>\n",
       "      <td>What are some differences between Latin Americ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256607</th>\n",
       "      <td>What is an inclined plane? What are examples o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300740</th>\n",
       "      <td>How can I prove that a negative number multipl...</td>\n",
       "      <td>5</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531674</th>\n",
       "      <td>How do I learn English step by step?</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139362</th>\n",
       "      <td>In what ways are you privileged and in what wa...</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702490</th>\n",
       "      <td>Is time travel possible? If yes how</td>\n",
       "      <td>6</td>\n",
       "      <td>Work &amp; Careers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  Topic number  \\\n",
       "528339                              How do I hack a wifi?             0   \n",
       "161450                                 Wwe is real fight?             6   \n",
       "699472                          What is written in vedas?             6   \n",
       "736752           Why don't women propose to men in India?             5   \n",
       "772144    Which car should I buy for my parents in India?             8   \n",
       "329727  Would there be trans people if society had no ...             0   \n",
       "467123                          What is a data scientist?             4   \n",
       "565569   I recently lost my phone. How can I get it back?             3   \n",
       "450954                        How do I use anonymous.com?             9   \n",
       "682524  What are the best Bollywood movies of 2016 so ...             1   \n",
       "251368                             How can learn English?             6   \n",
       "644404  What is the best strategy to increase engageme...             9   \n",
       "765818                         Why can't men wear tights?             5   \n",
       "786053  CSIM, Matlab, Java sim which would be best for...             9   \n",
       "348011     What is like to study international relations?             7   \n",
       "231021               Which is the best phone below 15000?             0   \n",
       "797148                   What will the afterlife be like?             7   \n",
       "322078                               How safe is Georgia?             0   \n",
       "697576             What is ink made from? How is it made?             0   \n",
       "50270   What are the most efficient methods for me to ...             6   \n",
       "165330  Do engineering classes depend on physics and c...             9   \n",
       "362543           Are dark matter and dark energy: energy?             8   \n",
       "513003  Are structural health monitoring researches sa...             7   \n",
       "80162   Can I use open source software for commercial ...             9   \n",
       "744948  Why can't I buy with my gift card balance on A...             4   \n",
       "140523  Are there any languages that are still spoken,...             2   \n",
       "749240                      How Subsea Wells are drilled?             3   \n",
       "10093                               How do you see PM2.5?             0   \n",
       "628946         What is it like to regret having children?             4   \n",
       "700965  What do you think about the BJP government not...             2   \n",
       "...                                                   ...           ...   \n",
       "477190  What are good books written in Tamil that have...             6   \n",
       "596301            How immediately come frog in rainy day?             2   \n",
       "622972                   Why isn't Quora listed in Klout?             9   \n",
       "75637   Do you really think what ever happens is as pe...             7   \n",
       "307044  What is the english translation for the word i...             6   \n",
       "334078            How does one deal with a bully at work?             4   \n",
       "550572        What is genetic drift? What are some types?             7   \n",
       "210962  Which hotels in ernakulam allow unmarried coup...             8   \n",
       "373899        Is Bitcoin mining still profitable in 2016?             2   \n",
       "587383  What is the most popular board game that is no...             3   \n",
       "506388    What is the single best excercise for your abs?             1   \n",
       "120229               What time does USPS usually deliver?             4   \n",
       "78277   Bitcoin in India: Where can I buy bitcoins in ...             8   \n",
       "472705  Wouldn't ISPs block forum sites without net ne...             9   \n",
       "250435  Why did Zeus trick Hades ?And he gave him the ...             8   \n",
       "264339          How can I become a professional listener?             0   \n",
       "669794  How big a problem is people mischievously edit...             4   \n",
       "407767                        Why do people bully others?             8   \n",
       "782464  How should we define an engaged user for Google+?             0   \n",
       "378393  What are the best colleges for studying econom...             7   \n",
       "136275  Where can I find public or free real-time or s...             6   \n",
       "236428                   How do I learn machine learning?             9   \n",
       "474798         How can I learn to speak English fluently?             6   \n",
       "765494  How will it be after death? Where does the sou...             1   \n",
       "627277  What are some differences between Latin Americ...             4   \n",
       "256607  What is an inclined plane? What are examples o...             0   \n",
       "300740  How can I prove that a negative number multipl...             5   \n",
       "531674               How do I learn English step by step?             2   \n",
       "139362  In what ways are you privileged and in what wa...             2   \n",
       "702490                Is time travel possible? If yes how             6   \n",
       "\n",
       "            Topic desc  \n",
       "528339      Technology  \n",
       "161450  Work & Careers  \n",
       "699472  Work & Careers  \n",
       "736752        Politics  \n",
       "772144          Travel  \n",
       "329727      Technology  \n",
       "467123   Relationships  \n",
       "565569      Activities  \n",
       "450954        Learning  \n",
       "682524      Life Style  \n",
       "251368  Work & Careers  \n",
       "644404        Learning  \n",
       "765818        Politics  \n",
       "786053        Learning  \n",
       "348011       Education  \n",
       "231021      Technology  \n",
       "797148       Education  \n",
       "322078      Technology  \n",
       "697576      Technology  \n",
       "50270   Work & Careers  \n",
       "165330        Learning  \n",
       "362543          Travel  \n",
       "513003       Education  \n",
       "80162         Learning  \n",
       "744948   Relationships  \n",
       "140523        Business  \n",
       "749240      Activities  \n",
       "10093       Technology  \n",
       "628946   Relationships  \n",
       "700965        Business  \n",
       "...                ...  \n",
       "477190  Work & Careers  \n",
       "596301        Business  \n",
       "622972        Learning  \n",
       "75637        Education  \n",
       "307044  Work & Careers  \n",
       "334078   Relationships  \n",
       "550572       Education  \n",
       "210962          Travel  \n",
       "373899        Business  \n",
       "587383      Activities  \n",
       "506388      Life Style  \n",
       "120229   Relationships  \n",
       "78277           Travel  \n",
       "472705        Learning  \n",
       "250435          Travel  \n",
       "264339      Technology  \n",
       "669794   Relationships  \n",
       "407767          Travel  \n",
       "782464      Technology  \n",
       "378393       Education  \n",
       "136275  Work & Careers  \n",
       "236428        Learning  \n",
       "474798  Work & Careers  \n",
       "765494      Life Style  \n",
       "627277   Relationships  \n",
       "256607      Technology  \n",
       "300740        Politics  \n",
       "531674        Business  \n",
       "139362        Business  \n",
       "702490  Work & Careers  \n",
       "\n",
       "[200001 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning these values back to the data frame.\n",
    "dataframe[\"Topic desc\"] = topic_no_to_topic\n",
    "# return each document as well as the assigned topic number and each topic description.\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is created using the following parameters:\n",
    " 1. n_components = 10\n",
    " 2. learning_decay = 0.5\n",
    " 3. random_state=1\n",
    " 4. max_df = 0.70 \n",
    " 5. min_df = 4\n",
    "    \n",
    "Based on the Log Likelihood and Perplexity values model 1 and model 3 are almost have equal performance. Eventhough the performance of the first model is slightly better than the model - 3 which is tuned based on the gridsearch parameters. \n",
    "\n",
    "Still we can increase the performance of the model by chaging and playing with above mentioned parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose LDA insted of NMF because of two reason.\n",
    "\n",
    "1. In NMF the performance matrix or efficiency can not be evaluated in terms of Log Likelihood and Perplexity values. Hence which makes it difficult for comparision of models with in the NMF and comparision with LDA model.\n",
    "2. LDA  adds a Dirichlet prior on top of the data generating process, meaning NMF qualitatively leads to worse mixtures. It fixes values for the probability vectors of the multinomials, whereas LDA allows the topics and words themselves to vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the new dataframe into csv file\n",
    "dataframe.to_csv(r'quora_supervised.csv', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
