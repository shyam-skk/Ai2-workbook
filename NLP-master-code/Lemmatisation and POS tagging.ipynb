{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "In contrast to stemming, lemmatization looks beyond word reduction, and considers a language's full vocabulary to apply a **morphological analysis** to words. This is the grammatical analysis of the formation of words from morphemes. \n",
    "\n",
    "For example, the lemma of **was** is **be** and the lemma of **mice** is **mouse**. The lemma of **meeting** might be **meet** or **meeting** depending on its use in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we import the `spaCy` library and the language model.\n",
    "\n",
    "Then we load the relevant language model. In this example, I'm using the **English language** model.\n",
    "\n",
    "The model will be stored in the instance called **nlp**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Alternatively we could load the English language library as follows\n",
    "# from spacy.lang.en import English\n",
    "# nlp = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to create a short sentence and assign it to a `spaCy` **document object** using the **nlp** model. A document object can be a sentence or a group of sentences and it can have an unlimited length. When the command `nlp` is applied to a string, spaCy tokenises the text and creates a document object.\n",
    "\n",
    "The following script creates a simple `spaCy` document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_object = nlp(u\"I like to jog. I hated it in my childhood though\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SpaCy` automatically breaks this document into tokens when a document is created using the **nlp** model.\n",
    "\n",
    "Let's see what tokens we have in our document, as well as the associated **parts-of-speech (POS)** tags using the `.pos_` attribute. I'll discuss POS tags in more detail shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "like VERB\n",
      "to PART\n",
      "jog VERB\n",
      ". PUNCT\n",
      "I PRON\n",
      "hated VERB\n",
      "it PRON\n",
      "in ADP\n",
      "my ADJ\n",
      "childhood NOUN\n",
      "though ADP\n"
     ]
    }
   ],
   "source": [
    "for token in doc_object:\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'd like to examine all of the root words from my sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -----> -PRON-\n",
      "like -----> like\n",
      "to -----> to\n",
      "jog -----> jog\n",
      ". -----> .\n",
      "I -----> -PRON-\n",
      "hated -----> hat\n",
      "it -----> -PRON-\n",
      "in -----> in\n",
      "my -----> -PRON-\n",
      "childhood -----> childhood\n",
      "though -----> though\n"
     ]
    }
   ],
   "source": [
    "for word in doc_object:\n",
    "    print(word.text + \" -----> \" + word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what happens with the words we used in the stemming example. I'll compare the root words identified by lemmatization versus stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caresses -----> caress \t VERB\n",
      "ponies -----> pony \t NOUN\n",
      "pony -----> pony \t NOUN\n",
      "cats -----> cat \t NOUN\n",
      "running -----> run \t VERB\n",
      "runner -----> runner \t NOUN\n",
      "climber -----> climber \t NOUN\n",
      "easily -----> easily \t ADV\n",
      "quickly -----> quickly \t ADV\n"
     ]
    }
   ],
   "source": [
    "sample_words = nlp(u\"caresses ponies pony cats running runner climber easily quickly\")\n",
    "\n",
    "for word in sample_words:\n",
    "    print(word.text + \" -----> \" + word.lemma_, \"\\t\", word.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, I've added the stemming output below.\n",
    "\n",
    "caresses ------> caress<br>\n",
    "ponies ------> poni<br>\n",
    "pony ------> poni<br>\n",
    "cats ------> cat<br>\n",
    "running ------> run<br>\n",
    "runner ------> runner<br>\n",
    "climber ------> climber<br>\n",
    "easily ------> easili<br>\n",
    "quickly ------> quickli<br>\n",
    "\n",
    "We can see that unlike stemming where the root we got was **poni** for **ponies**, the roots that we arrived at through lemmatization are actual words in the English dictionary.\n",
    "\n",
    "Lemmatization converts words in the second or third forms to their first form variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm now going to create a simple **function** to input some NLP text and I'll then use f-string formatting to tidy up my output from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lemmatization(text_to_convert):\n",
    "    for token in text_to_convert:\n",
    "        print (f\"{token.text:{15}} {token.lemma_:{30}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll create an NLP sentence and call the **create_lemmatization** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The             the                           \n",
      "brown           brown                         \n",
      "fox             fox                           \n",
      "is              be                            \n",
      "quick           quick                         \n",
      "and             and                           \n",
      "he              -PRON-                        \n",
      "is              be                            \n",
      "jumping         jump                          \n",
      "over            over                          \n",
      "the             the                           \n",
      "lazy            lazy                          \n",
      "dog             dog                           \n"
     ]
    }
   ],
   "source": [
    "doc_object = nlp(u\"The brown fox is quick and he is jumping over the lazy dog\")\n",
    "# Call the lemmatization function with my sentence\n",
    "create_lemmatization(doc_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the lemmatization of **is** is **be**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech\n",
    "\n",
    "Processing raw text intelligently is difficult. Lots of words that look completely different can mean almost the same thing. The same words in a different order can mean something completely different. Even splitting text into useful word-like units can be difficult in many languages. While it's possible to solve some problems starting from only the raw characters, it's usually better to use linguistic knowledge to add useful information. That's exactly what `spaCy` is designed to do: you put in raw text, and get back a `Doc` object, that comes with a variety of annotations.\n",
    "\n",
    "A **Part-Of-Speech Tagger (POS Tagger)** reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc., although generally computational applications use more fine-grained POS tags like 'noun-plural'.\n",
    "\n",
    "In this section we'll look at POS tags in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm assuming that the `spaCy` library and the language model has been loaded. Refer to the code above if you haven't loaded the English language library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View token tags\n",
    "We can obtain a particular token by its index position.\n",
    "* To view the coarse POS tag use `token.pos_`\n",
    "* To view the fine-grained tag use `token.tag_`\n",
    "* To view the description of either type of tag use `spacy.explain(tag)`\n",
    "\n",
    "Note that `token.pos` and `token.tag` commands return integer hash values. By adding the underscores we get the text (string) equivalent that lives in **doc.vocab**. So the data returned by adding the underscore is more meaningful to us than just the integer hash value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, lets have a look at the full ine of text that we'll now work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like to jog. I hated it in my childhood though\n"
     ]
    }
   ],
   "source": [
    "doc_object = nlp(u\"I like to jog. I hated it in my childhood though\")\n",
    "print(doc_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `doc` object contains information on the **predictive POS tag** as well as other interexting attributes. We can easily show the POS tags generated by `spaCy` through a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I                    PRON       PRP   pronoun, personal\n",
      " like                 VERB       VBP   verb, non-3rd person singular present\n",
      " to                   PART       TO    infinitival to\n",
      " jog                  VERB       VB    verb, base form\n",
      " .                    PUNCT      .     punctuation mark, sentence closer\n",
      " I                    PRON       PRP   pronoun, personal\n",
      " hated                VERB       VBD   verb, past tense\n",
      " it                   PRON       PRP   pronoun, personal\n",
      " in                   ADP        IN    conjunction, subordinating or preposition\n",
      " my                   ADJ        PRP$  pronoun, possessive\n",
      " childhood            NOUN       NN    noun, singular or mass\n",
      " though               ADP        IN    conjunction, subordinating or preposition\n"
     ]
    }
   ],
   "source": [
    "for token in doc_object:\n",
    "        print(f\" {token.text:{20}} {token.pos_:{10}} {token.tag_:{5}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pos_` tag represents the **part-of-speech** tag for each word. For example lets examine the word **hated**.\n",
    "\n",
    "We can see that the **POS tag** or the **course-grained POS tag** for **hated** is **VERB** and this is correct since **hated** is a verb.\n",
    "\n",
    "The **fine-grained POS tag** for the word **hated** is **VBD**. We can use the command `spacy.explain()` to show more information on what the **VBD** tage means. \n",
    "\n",
    "The full explanation of **VBD** is **verb, past tense**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every token is assigned a course-grained POS Tag from the following list:\n",
    "\n",
    "\n",
    "<table><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n",
    "    \n",
    "<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n",
    "<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n",
    "<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>*$, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù*</td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n",
    "<tr><td>SPACE</td><td>space</td></tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tokens are subsequently given a fine-grained tag as determined by morphology:\n",
    "<table>\n",
    "<tr><th>POS</th><th>Description</th><th>Fine-grained Tag</th><th>Description</th><th>Morphology</th></tr>\n",
    "<tr><td>ADJ</td><td>adjective</td><td>AFX</td><td>affix</td><td>Hyph=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJ</td><td>adjective</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJR</td><td>adjective, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJS</td><td>adjective, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PDT</td><td>predeterminer</td><td>AdjType=pdt PronType=prn</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PRP\\$</td><td>pronoun, possessive</td><td>PronType=prs Poss=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WDT</td><td>wh-determiner</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>Poss=yes PronType=int rel</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>IN</td><td>conjunction, subordinating or preposition</td><td></td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>EX</td><td>existential there</td><td>AdvType=ex</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RB</td><td>adverb</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBR</td><td>adverb, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBS</td><td>adverb, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>WRB</td><td>wh-adverb</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>CC</td><td>conjunction, coordinating</td><td>ConjType=coor</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>DT</td><td>determiner</td><td></td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>UH</td><td>interjection</td><td></td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>NN</td><td>noun, singular or mass</td><td>Number=sing</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>NNS</td><td>noun, plural</td><td>Number=plur</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>WP</td><td>wh-pronoun, personal</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>CD</td><td>cardinal number</td><td>NumType=card</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>POS</td><td>possessive ending</td><td>Poss=yes</td></tr>\n",
    "<tr><td>PART</td><td></td><td>RP</td><td>adverb, particle</td><td></td></tr>\n",
    "<tr><td>PART</td><td></td><td>TO</td><td>infinitival to</td><td>PartType=inf VerbForm=inf</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>PRP</td><td>pronoun, personal</td><td>PronType=prs</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>NNP</td><td>noun, proper singular</td><td>NounType=prop Number=sign</td></tr>\n",
    "<tr><td>PROPN</td><td></td><td>NNPS</td><td>noun, proper plural</td><td>NounType=prop Number=plur</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>-LRB-</td><td>left round bracket</td><td>PunctType=brck PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>-RRB-</td><td>right round bracket</td><td>PunctType=brck PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>,</td><td>punctuation mark, comma</td><td>PunctType=comm</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>:</td><td>punctuation mark, colon or ellipsis</td><td></td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>.</td><td>punctuation mark, sentence closer</td><td>PunctType=peri</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>''</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>\"\"</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>``</td><td>opening quotation mark</td><td>PunctType=quot PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>HYPH</td><td>punctuation mark, hyphen</td><td>PunctType=dash</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>LS</td><td>list item marker</td><td>NumType=ord</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>NFP</td><td>superfluous punctuation</td><td></td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>#</td><td>symbol, number sign</td><td>SymType=numbersign</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>\\$</td><td>symbol, currency</td><td>SymType=currency</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>SYM</td><td>symbol</td><td></td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>BES</td><td>auxiliary \"be\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>HVS</td><td>forms of \"have\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>MD</td><td>verb, modal auxiliary</td><td>VerbType=mod</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VB</td><td>verb, base form</td><td>VerbForm=inf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBD</td><td>verb, past tense</td><td>VerbForm=fin Tense=past</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBG</td><td>verb, gerund or present participle</td><td>VerbForm=part Tense=pres Aspect=prog</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBN</td><td>verb, past participle</td><td>VerbForm=part Tense=past Aspect=perf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBP</td><td>verb, non-3rd person singular present</td><td>VerbForm=fin Tense=pres</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBZ</td><td>verb, 3rd person singular present</td><td>VerbForm=fin Tense=pres Number=sing Person=3</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>ADD</td><td>email</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>FW</td><td>foreign word</td><td>Foreign=yes</td></tr>\n",
    "<tr><td>X</td><td></td><td>GW</td><td>additional word in multi-word expression</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>XX</td><td>unknown</td><td></td></tr>\n",
    "<tr><td>SPACE</td><td>space</td><td>_SP</td><td>space</td><td></td></tr>\n",
    "<tr><td></td><td></td><td>NIL</td><td>missing tag</td><td></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a link to all the speech tags available through `spaCy`. https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with POS Tags\n",
    "In the English language, the same string of characters can have different meanings, even within the same sentence. For this reason, morphology is important. **spaCy** uses machine learning algorithms to best predict the use of a token in a sentence. Is *\"I read library books\"* present or past tense? Is *read* a verb or a noun?\n",
    "\n",
    "Lets look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I          PRON       PRP        pronoun, personal   \n",
      " read       VERB       VBP        verb, non-3rd person singular present\n",
      " library    NOUN       NN         noun, singular or mass\n",
      " books      NOUN       NNS        noun, plural        \n",
      " .          PUNCT      .          punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "doc_object = nlp(u\"I read library books.\")\n",
    "for word in doc_object:\n",
    "    print(f\" {word.text:{10}} {word.pos_:{10}} {word.tag_:{10}} {spacy.explain(word.tag_):{20}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`spaCy` detects that the word **read** in this sentence is in the **present** tense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I          PRON       PRP        pronoun, personal   \n",
      " read       VERB       VBD        verb, past tense    \n",
      " a          DET        DT         determiner          \n",
      " library    NOUN       NN         noun, singular or mass\n",
      " book       NOUN       NN         noun, singular or mass\n",
      " .          PUNCT      .          punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "doc_object = nlp(u\"I read a library book.\")\n",
    "for word in doc_object:\n",
    "    print(f\" {word.text:{10}} {word.pos_:{10}} {word.tag_:{10}} {spacy.explain(word.tag_):{20}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it detects that **read** in this example is in the past tense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I          PRON       PRP        pronoun, personal   \n",
      " am         VERB       VBP        verb, non-3rd person singular present\n",
      " reading    VERB       VBG        verb, gerund or present participle\n",
      " a          DET        DT         determiner          \n",
      " library    NOUN       NN         noun, singular or mass\n",
      " book       NOUN       NN         noun, singular or mass\n",
      " .          PUNCT      .          punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "doc_object = nlp(u\"I am reading a library book.\")\n",
    "for word in doc_object:\n",
    "    print(f\" {word.text:{10}} {word.pos_:{10}} {word.tag_:{10}} {spacy.explain(word.tag_):{20}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that `spaCy` can pick up the change in tense if we rephrase the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tagging can be useful if we have words or tokens that can have multiple POS tags. For instance, the word \"google\" can be used as both a noun and verb, depending upon the context of the sentence. While processing natural language, it is important to identify this difference. \n",
    "\n",
    "Fortunately, `spaCy` comes pre-built with machine learning algorithms that, depending upon the context (surrounding words), is capable of returning the correct POS tag for the word.\n",
    "\n",
    "Let's have a look at the **google** example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_object = nlp(u\"Can you google it?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets examine the POS tags for the word **google** in this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google\n"
     ]
    }
   ],
   "source": [
    "word = doc_object[2]\n",
    "print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " google     VERB       VB         verb, base form     \n"
     ]
    }
   ],
   "source": [
    "print(f\" {word.text:{10}} {word.pos_:{10}} {word.tag_:{10}} {spacy.explain(word.tag_):{20}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, the word \"google\" has been correctly identified as a verb.\n",
    "\n",
    "Now let's change the context of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google\n"
     ]
    }
   ],
   "source": [
    "doc_object = nlp(u\"Can you search for it on google?\")\n",
    "word = doc_object[6]\n",
    "print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " google     PROPN      NNP        noun, proper singular\n"
     ]
    }
   ],
   "source": [
    "print(f\" {word.text:{10}} {word.pos_:{10}} {word.tag_:{10}} {spacy.explain(word.tag_):{20}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the word **google** is being used as a noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting POS Tags\n",
    "\n",
    "The `.count_by()` method accepts a specific token attribute as its argument, and returns a frequency count of the given attribute as a dictionary object. The method takes `spacy.attrs.POS` as a parameter value. \n",
    "\n",
    "Keys in the dictionary are the integer values of the given attribute ID, and values are the frequency. Counts of zero are not included.\n",
    "\n",
    "The `spacy.attrs.POS` command provides information on the **course-grained** POS tag for each word in the document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{96: 1, 99: 3, 84: 2, 83: 1, 91: 1, 93: 1, 94: 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_object = nlp(u\"I like to jog. I hated it in my childhood though\")\n",
    "\n",
    "# Count the frequencies of different coarse-grained POS tags in the sentence\n",
    "POS_frequency = doc_object.count_by(spacy.attrs.POS)\n",
    "POS_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output, we can see the ID of the **POS tags** along with their frequencies of occurrence. The text of the POS tag can be displayed by passing the ID of the tag to the vocabulary of the `spaCy` document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PUNCT'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_object.vocab[96].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that there is **one** punctuation in the sentence.\n",
    "\n",
    "We can use a loop to display the frequency of each POS tag in the sentence. **POS_frequency** is a dictionary object so we need to use the `.items()` command to access each element within it. The content of **POS_frequency** contains the **POS tag ID** followed by the **number of occurrences** of that ID. So we assign a variable to each item within the loop. The text of the **POS tag** can be displayed by passing the ID of the tag to the vocabulary of the **spaCy document object**. The vocab object provides a lookup table containing lexemes etc. See this link for more information https://spacy.io/api/vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         96 PUNCT      1\n",
      "         99 VERB       3\n",
      "         84 ADP        2\n",
      "         83 ADJ        1\n",
      "         91 NOUN       1\n",
      "         93 PART       1\n",
      "         94 PRON       3\n"
     ]
    }
   ],
   "source": [
    "# Using the \".items()\" command accesses each item in the dictionary\n",
    "for tag_id, occurrences in POS_frequency.items():\n",
    "        print(f\" {tag_id:{10}} {doc_object.vocab[tag_id].text:{10}} {occurrences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(POS_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sort the contents of `POS_frequency` first before we analyse its contents using the `sorted` command.\n",
    "\n",
    "**Note:** tags are not assigned to spaces unless there are two or more of them. Single spaces are not assigned tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         83 ADJ        1\n",
      "         84 ADP        2\n",
      "         91 NOUN       1\n",
      "         93 PART       1\n",
      "         94 PRON       3\n",
      "         96 PUNCT      1\n",
      "         99 VERB       3\n"
     ]
    }
   ],
   "source": [
    "for tag_id, occurrences in sorted (POS_frequency.items()):\n",
    "        print(f\" {tag_id:{10}} {doc_object.vocab[tag_id].text:{10}} {occurrences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can provide details on the **fine-granined** POS tag count too.\n",
    "\n",
    "The `spacy.attrs.TAG` command provides information on the **fine-grained** POS tag for each word in the document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1292078113972184607 IN         2\n",
      "  4062917326063685704 PRP$       1\n",
      "  5595707737748328492 TO         1\n",
      "  9188597074677201817 VBP        1\n",
      " 12646065887601541794 .          1\n",
      " 13656873538139661788 PRP        3\n",
      " 14200088355797579614 VB         1\n",
      " 15308085513773655218 NN         1\n",
      " 17109001835818727656 VBD        1\n"
     ]
    }
   ],
   "source": [
    "# Get counts on each fine-grained POS tag for the document object\n",
    "fine_grained_POS = doc_object.count_by(spacy.attrs.TAG)\n",
    "\n",
    "for tag_id, occurrences in sorted (fine_grained_POS.items()):\n",
    "    print(f\" {tag_id:{20}} {doc_object.vocab[tag_id].text:{10}} {occurrences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is sorted on the tag ID.\n",
    "\n",
    "We can look at the **syntactic dependencies** of the document object using the `spacy.attrs.dep` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       397 advmod    : 1\n",
      "       402 aux       : 1\n",
      "       413 dobj      : 1\n",
      "       426 nsubj     : 2\n",
      "       436 pobj      : 1\n",
      "       437 poss      : 1\n",
      "       440 prep      : 1\n",
      "       442 punct     : 1\n",
      "       446 xcomp     : 1\n",
      "8206900633647566924 ROOT      : 2\n"
     ]
    }
   ],
   "source": [
    "# Count the different dependencies:\n",
    "syn_dep_count = doc_object.count_by(spacy.attrs.DEP)\n",
    "\n",
    "for tag_id, occurrences in sorted(syn_dep_count.items()):\n",
    "    print(f'{tag_id:{10}} {doc_object.vocab[tag_id].text:{10}}: {occurrences}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing POS Tags\n",
    "\n",
    "Visualising POS tags in a graphical way is extremely easy. The `displacy` module from the spacy library is used for this purpose. \n",
    "\n",
    "To visualise the POS tags inside the Jupyter notebook, we need to call the `render` method from the `displacy` module and pass the spacy document object to it. We must set the style of the visualisation, and the `jupyter` attribute to `True`. I've already covered visualisation in the **Tokenisation** lecture so refer to it for further information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1040\" height=\"272.0\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">like</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">jog.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">hated</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">my</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">childhood</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">though</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,92.0 130.0,92.0 130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M160,137.0 C160,47.0 315.0,47.0 315.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M315.0,139.0 L323.0,127.0 307.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M430,137.0 C430,92.0 490.0,92.0 490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,139.0 L422,127.0 438,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M520,137.0 C520,92.0 580.0,92.0 580.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M580.0,139.0 L588.0,127.0 572.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M520,137.0 C520,47.0 675.0,47.0 675.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M675.0,139.0 L683.0,127.0 667.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M790,137.0 C790,92.0 850.0,92.0 850.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,139.0 L782,127.0 798,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M700,137.0 C700,47.0 855.0,47.0 855.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M855.0,139.0 L863.0,127.0 847.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M520,137.0 C520,2.0 950.0,2.0 950.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,139.0 L958.0,127.0 942.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc_object = nlp(u\"I like to jog. I hated it in my childhood though\")\n",
    "displacy.render(doc_object, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to visualise the POS tags outside of Jupyter notebook, then you need to call the `serve` method. The plot for POS tags will be printed in HTML format inside your default browser. Execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Serving on port 5000...\n",
      "    Using the 'dep' visualizer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displacy.serve(doc_object, style='dep', options={'distance': 120})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the dependency tree, type the following address into your browser: http://127.0.0.1:5000/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
