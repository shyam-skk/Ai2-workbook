{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='Project-Gutenberg.txt' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text_file = open(\"Project-Gutenberg.txt\")\n",
    "my_text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contents = my_text_file.read()\n",
    "my_text_file.seek(0)\n",
    "all_my_lines = my_text_file.readlines()\n",
    "my_text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7182\n"
     ]
    }
   ],
   "source": [
    "print(len(all_my_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Project Gutenberg EBook of The World Set Free, by Herbert George Wells\\n', '\\n', 'This eBook is for the use of anyone anywhere at no cost and with\\n', 'almost no restrictions whatsoever.  You may copy it, give it away or\\n', 're-use it under the terms of the Project Gutenberg License included\\n', 'with this eBook or online at www.gutenberg.org\\n', '\\n', '\\n', 'Title: The World Set Free\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print(all_my_lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question whether a Leblanc is still possible, the question whether\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_my_lines[120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the English language library\n",
    "import spacy\n",
    "# This will take a while to load initially\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_arraay=[]\n",
    "for line in all_my_lines:\n",
    "    book_arraay.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question whether a Leblanc is still possible, the question whether\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(book_arraay[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_object = nlp(book_arraay[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The question whether a Leblanc is still possible, the question whether"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        | DET        |                  412 | determiner\n",
      "Project    | PROPN      |  7037928807040764755 | proper noun\n",
      "Gutenberg  | PROPN      |  7037928807040764755 | proper noun\n",
      "EBook      | PROPN      |  8206900633647566924 | proper noun\n",
      "of         | ADP        |                  440 | adposition\n",
      "The        | DET        |                  412 | determiner\n",
      "World      | PROPN      |  7037928807040764755 | proper noun\n",
      "Set        | PROPN      |  7037928807040764755 | proper noun\n",
      "Free       | PROPN      |                  436 | proper noun\n",
      ",          | PUNCT      |                  442 | punctuation\n",
      "by         | ADP        |                  440 | adposition\n",
      "Herbert    | PROPN      |  7037928807040764755 | proper noun\n",
      "George     | PROPN      |  7037928807040764755 | proper noun\n",
      "Wells      | PROPN      |                  436 | proper noun\n",
      "\n",
      "\n",
      "         | SPACE      |                    0 | space\n",
      "This       | DET        |                  412 | determiner\n",
      "eBook      | PROPN      |                  426 | proper noun\n",
      "is         | VERB       |  8206900633647566924 | verb\n",
      "for        | ADP        |                  440 | adposition\n",
      "the        | DET        |                  412 | determiner\n",
      "us         | PRON       |                  436 | pronoun\n"
     ]
    }
   ],
   "source": [
    "#print each token individually\n",
    "for token in doc_object:\n",
    "    #show token\n",
    "    print(f\"{token.text:{10}} | {token.pos_:{10}} | {token.dep:{20}} | {spacy.explain(token.pos_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oject',\n",
       " 'utenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'orld',\n",
       " 'et',\n",
       " 'ee',\n",
       " 'erbert',\n",
       " 'eorge',\n",
       " 'ells',\n",
       " 'is',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'or',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'ost',\n",
       " 'and',\n",
       " 'ith',\n",
       " 'almost',\n",
       " 'estrictions',\n",
       " 'atsoever',\n",
       " 'ou',\n",
       " 'ay',\n",
       " 'opy',\n",
       " 'it',\n",
       " 'ive',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 'use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'erms',\n",
       " 'of',\n",
       " 'oject',\n",
       " 'utenberg',\n",
       " 'icense',\n",
       " 'included',\n",
       " 'ith',\n",
       " 'is',\n",
       " 'eBook',\n",
       " 'or',\n",
       " 'online',\n",
       " 'at',\n",
       " 'utenberg',\n",
       " 'org',\n",
       " 'itle',\n",
       " 'orld',\n",
       " 'et',\n",
       " 'ee',\n",
       " 'Author',\n",
       " 'erbert',\n",
       " 'eorge',\n",
       " 'ells',\n",
       " 'elease',\n",
       " 'ate',\n",
       " 'ebruary',\n",
       " 'EBook',\n",
       " 'ast',\n",
       " 'Updated',\n",
       " 'eptember',\n",
       " 'anguage',\n",
       " 'English',\n",
       " 'aracter',\n",
       " 'et',\n",
       " 'encoding',\n",
       " 'UTF',\n",
       " 'ART',\n",
       " 'OF',\n",
       " 'IS',\n",
       " 'OJECT',\n",
       " 'UTENBERG',\n",
       " 'EBOOK',\n",
       " 'ORLD',\n",
       " 'ET',\n",
       " 'EE',\n",
       " 'oduced',\n",
       " 'arles',\n",
       " 'eller',\n",
       " 'and',\n",
       " 'avid',\n",
       " 'idger',\n",
       " 'ORLD',\n",
       " 'ET',\n",
       " 'EE',\n",
       " 'ELLS',\n",
       " 'Are',\n",
       " 'All',\n",
       " 'ings',\n",
       " 'at',\n",
       " 'ake',\n",
       " 'And',\n",
       " 'ass',\n",
       " 'iving',\n",
       " 'Upon',\n",
       " 'idden',\n",
       " 'ission',\n",
       " 'Out',\n",
       " 'Open',\n",
       " 'ea',\n",
       " 'ederick',\n",
       " 'oddy',\n",
       " 'Interpretation',\n",
       " 'Of',\n",
       " 'adium',\n",
       " 'is',\n",
       " 'ory',\n",
       " 'ich',\n",
       " 'Owes',\n",
       " 'ong',\n",
       " 'assages',\n",
       " 'Eleventh',\n",
       " 'apter',\n",
       " 'Of',\n",
       " 'at',\n",
       " 'ook',\n",
       " 'Acknowledges',\n",
       " 'And',\n",
       " 'Inscribes',\n",
       " 'Itself',\n",
       " 'EFACE',\n",
       " 'ORLD',\n",
       " 'ET',\n",
       " 'EE',\n",
       " 'as',\n",
       " 'itten',\n",
       " 'in',\n",
       " 'and',\n",
       " 'ublished',\n",
       " 'early',\n",
       " 'in',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'atest',\n",
       " 'of',\n",
       " 'eries',\n",
       " 'of',\n",
       " 'ee',\n",
       " 'antasias',\n",
       " 'of',\n",
       " 'ossibility',\n",
       " 'ories',\n",
       " 'ich',\n",
       " 'all',\n",
       " 'urn',\n",
       " 'on',\n",
       " 'ossible',\n",
       " 'evelopments',\n",
       " 'in',\n",
       " 'uture',\n",
       " 'of',\n",
       " 'ome',\n",
       " 'ontemporary',\n",
       " 'orce',\n",
       " 'or',\n",
       " 'oup',\n",
       " 'of',\n",
       " 'orces',\n",
       " 'orld',\n",
       " 'et',\n",
       " 'ee',\n",
       " 'as',\n",
       " 'itten',\n",
       " 'under',\n",
       " 'immediate',\n",
       " 'adow',\n",
       " 'of',\n",
       " 'eat',\n",
       " 'ar',\n",
       " 'Every',\n",
       " 'intelligent',\n",
       " 'erson',\n",
       " 'in',\n",
       " 'orld',\n",
       " 'elt',\n",
       " 'at',\n",
       " 'isaster',\n",
       " 'as',\n",
       " 'impending',\n",
       " 'and',\n",
       " 'ew',\n",
       " 'ay',\n",
       " 'of',\n",
       " 'averting',\n",
       " 'it',\n",
       " 'ut',\n",
       " 'ew',\n",
       " 'of',\n",
       " 'us',\n",
       " 'ealised',\n",
       " 'in',\n",
       " 'earlier',\n",
       " 'alf',\n",
       " 'of',\n",
       " 'ow',\n",
       " 'ear',\n",
       " 'ash',\n",
       " 'as',\n",
       " 'us',\n",
       " 'eader',\n",
       " 'ill',\n",
       " 'amused',\n",
       " 'ind',\n",
       " 'at',\n",
       " 'ere',\n",
       " 'it',\n",
       " 'is',\n",
       " 'ut',\n",
       " 'off',\n",
       " 'until',\n",
       " 'ear',\n",
       " 'ay',\n",
       " 'aturally',\n",
       " 'ant',\n",
       " 'ow',\n",
       " 'eason',\n",
       " 'or',\n",
       " 'at',\n",
       " 'ill',\n",
       " 'eem',\n",
       " 'ow',\n",
       " 'uite',\n",
       " 'extraordinary',\n",
       " 'elay',\n",
       " 'As',\n",
       " 'ophet',\n",
       " 'author',\n",
       " 'ust',\n",
       " 'onfess',\n",
       " 'as',\n",
       " 'always',\n",
       " 'een',\n",
       " 'inclined',\n",
       " 'ather',\n",
       " 'ow',\n",
       " 'ophet',\n",
       " 'ar',\n",
       " 'aeroplane',\n",
       " 'in',\n",
       " 'orld',\n",
       " 'of',\n",
       " 'eality',\n",
       " 'or',\n",
       " 'example',\n",
       " 'eat',\n",
       " 'orecast',\n",
       " 'in',\n",
       " 'Anticipations',\n",
       " 'about',\n",
       " 'enty',\n",
       " 'ears',\n",
       " 'or',\n",
       " 'uppose',\n",
       " 'esire',\n",
       " 'ot',\n",
       " 'ock',\n",
       " 'eptical',\n",
       " 'eader',\n",
       " 'ense',\n",
       " 'of',\n",
       " 'use',\n",
       " 'and',\n",
       " 'ont',\n",
       " 'and',\n",
       " 'erhaps',\n",
       " 'ess',\n",
       " 'editable',\n",
       " 'isposition',\n",
       " 'edge',\n",
       " 'ave',\n",
       " 'omething',\n",
       " 'ith',\n",
       " 'is',\n",
       " 'ating',\n",
       " 'orward',\n",
       " 'of',\n",
       " 'one',\n",
       " 'ain',\n",
       " 'events',\n",
       " 'ut',\n",
       " 'in',\n",
       " 'articular',\n",
       " 'ase',\n",
       " 'of',\n",
       " 'orld',\n",
       " 'et',\n",
       " 'ee',\n",
       " 'ere',\n",
       " 'as',\n",
       " 'ink',\n",
       " 'another',\n",
       " 'otive',\n",
       " 'in',\n",
       " 'olding',\n",
       " 'eat',\n",
       " 'ar',\n",
       " 'ack',\n",
       " 'and',\n",
       " 'at',\n",
       " 'as',\n",
       " 'allow',\n",
       " 'emist',\n",
       " 'et',\n",
       " 'ell',\n",
       " 'orward',\n",
       " 'ith',\n",
       " 'is',\n",
       " 'iscovery',\n",
       " 'of',\n",
       " 'elease',\n",
       " 'of',\n",
       " 'atomic',\n",
       " 'energy',\n",
       " 'or',\n",
       " 'or',\n",
       " 'at',\n",
       " 'atter',\n",
       " 'ay',\n",
       " 'one',\n",
       " 'oo',\n",
       " 'ate',\n",
       " 'or',\n",
       " 'at',\n",
       " 'owning',\n",
       " 'evolution',\n",
       " 'in',\n",
       " 'uman',\n",
       " 'otentialities',\n",
       " 'And',\n",
       " 'apart',\n",
       " 'om',\n",
       " 'is',\n",
       " 'ocrastination',\n",
       " 'of',\n",
       " 'over',\n",
       " 'orty',\n",
       " 'ears',\n",
       " 'uess',\n",
       " 'at',\n",
       " 'opening',\n",
       " 'ase',\n",
       " 'of',\n",
       " 'ar',\n",
       " 'as',\n",
       " 'airly',\n",
       " 'ucky',\n",
       " 'orecast',\n",
       " 'of',\n",
       " 'an',\n",
       " 'alliance',\n",
       " 'of',\n",
       " 'entral',\n",
       " 'Empires',\n",
       " 'opening',\n",
       " 'ampaign',\n",
       " 'ough',\n",
       " 'etherlands',\n",
       " 'and',\n",
       " 'espatch',\n",
       " 'of',\n",
       " 'itish',\n",
       " 'Expeditionary',\n",
       " 'orce',\n",
       " 'ere',\n",
       " 'all',\n",
       " 'ustified',\n",
       " 'efore',\n",
       " 'ook',\n",
       " 'ad',\n",
       " 'een',\n",
       " 'ublished',\n",
       " 'ix',\n",
       " 'onths',\n",
       " 'And',\n",
       " 'opening',\n",
       " 'ection',\n",
       " 'of',\n",
       " 'apter',\n",
       " 'econd',\n",
       " 'emains',\n",
       " 'ow',\n",
       " 'after',\n",
       " 'eality',\n",
       " 'as',\n",
       " 'appened',\n",
       " 'airly',\n",
       " 'adequate',\n",
       " 'iagnosis',\n",
       " 'of',\n",
       " 'essentials',\n",
       " 'of',\n",
       " 'atter',\n",
       " 'One',\n",
       " 'appy',\n",
       " 'it',\n",
       " 'in',\n",
       " 'apter',\n",
       " 'econd',\n",
       " 'ection',\n",
       " 'on',\n",
       " 'ich',\n",
       " 'iter',\n",
       " 'ay',\n",
       " 'ongratulate',\n",
       " 'imself',\n",
       " 'is',\n",
       " 'orecast',\n",
       " 'at',\n",
       " 'under',\n",
       " 'odern',\n",
       " 'onditions',\n",
       " 'it',\n",
       " 'ould',\n",
       " 'uite',\n",
       " 'impossible',\n",
       " 'or',\n",
       " 'any',\n",
       " 'eat',\n",
       " 'eneral',\n",
       " 'emerge',\n",
       " 'upremacy',\n",
       " 'and',\n",
       " 'oncentrate',\n",
       " 'enthusiasm',\n",
       " 'of',\n",
       " 'armies',\n",
       " 'of',\n",
       " 'either',\n",
       " 'ide',\n",
       " 'ere',\n",
       " 'ould',\n",
       " 'Alexanders',\n",
       " 'or',\n",
       " 'apoleons',\n",
       " 'And',\n",
       " 'oon',\n",
       " 'eard',\n",
       " 'ientific',\n",
       " 'orps',\n",
       " 'uttering',\n",
       " 'ese',\n",
       " 'old',\n",
       " 'ools',\n",
       " 'exactly',\n",
       " 'as',\n",
       " 'it',\n",
       " 'is',\n",
       " 'ere',\n",
       " 'oretold',\n",
       " 'ese',\n",
       " 'owever',\n",
       " 'are',\n",
       " 'all',\n",
       " 'etails',\n",
       " 'and',\n",
       " 'isses',\n",
       " 'in',\n",
       " 'ory',\n",
       " 'ar',\n",
       " 'outnumber',\n",
       " 'its',\n",
       " 'It',\n",
       " 'is',\n",
       " 'ain',\n",
       " 'esis',\n",
       " 'ich',\n",
       " 'is',\n",
       " 'ill',\n",
       " 'of',\n",
       " 'interest',\n",
       " 'ow',\n",
       " 'esis',\n",
       " 'at',\n",
       " 'ecause',\n",
       " 'of',\n",
       " 'evelopment',\n",
       " 'of',\n",
       " 'ientific',\n",
       " 'owledge',\n",
       " 'eparate',\n",
       " 'overeign',\n",
       " 'ates',\n",
       " 'and',\n",
       " 'eparate',\n",
       " 'overeign',\n",
       " 'empires',\n",
       " 'are',\n",
       " 'onger',\n",
       " 'ossible',\n",
       " 'in',\n",
       " 'orld',\n",
       " 'at',\n",
       " 'attempt',\n",
       " 'eep',\n",
       " 'on',\n",
       " 'ith',\n",
       " 'old',\n",
       " 'em',\n",
       " 'is',\n",
       " 'eap',\n",
       " 'isaster',\n",
       " 'upon',\n",
       " 'isaster',\n",
       " 'or',\n",
       " 'ankind',\n",
       " 'and',\n",
       " 'erhaps',\n",
       " 'estroy',\n",
       " 'our',\n",
       " 'ace',\n",
       " 'altogether',\n",
       " 'emaining',\n",
       " 'interest',\n",
       " 'of',\n",
       " 'is',\n",
       " 'ook',\n",
       " 'ow',\n",
       " 'is',\n",
       " 'ustained',\n",
       " 'alidity',\n",
       " 'of',\n",
       " 'is',\n",
       " 'esis',\n",
       " 'and',\n",
       " 'iscussion',\n",
       " 'of',\n",
       " 'ossible',\n",
       " 'ending',\n",
       " 'of',\n",
       " 'ar',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'ave',\n",
       " 'upposed',\n",
       " 'ort',\n",
       " 'of',\n",
       " 'epidemic',\n",
       " 'of',\n",
       " 'anity',\n",
       " 'eak',\n",
       " 'out',\n",
       " 'among',\n",
       " 'ulers',\n",
       " 'of',\n",
       " 'ates',\n",
       " 'and',\n",
       " 'eaders',\n",
       " 'of',\n",
       " 'ankind',\n",
       " 'ave',\n",
       " 'epresented',\n",
       " 'ative',\n",
       " 'ommon',\n",
       " 'ense',\n",
       " 'of',\n",
       " 'ench',\n",
       " 'ind',\n",
       " 'and',\n",
       " 'of',\n",
       " 'English',\n",
       " 'ind',\n",
       " 'or',\n",
       " 'anifestly',\n",
       " 'ing',\n",
       " 'Egbert',\n",
       " 'is',\n",
       " 'eant',\n",
       " 'od',\n",
       " 'Englishman',\n",
       " 'eading',\n",
       " 'ankind',\n",
       " 'owards',\n",
       " 'old',\n",
       " 'and',\n",
       " 'esolute',\n",
       " 'effort',\n",
       " 'of',\n",
       " 'alvage',\n",
       " 'and',\n",
       " 'econstruction',\n",
       " 'Instead',\n",
       " 'of',\n",
       " 'ich',\n",
       " 'as',\n",
       " 'ool',\n",
       " 'ook',\n",
       " 'ootnotes',\n",
       " 'ay',\n",
       " 'ompare',\n",
       " 'ay',\n",
       " 'ewspaper',\n",
       " 'Instead',\n",
       " 'of',\n",
       " 'ank',\n",
       " 'and',\n",
       " 'onourable',\n",
       " 'athering',\n",
       " 'of',\n",
       " 'eading',\n",
       " 'en',\n",
       " 'Englishman',\n",
       " 'eeting',\n",
       " 'erman',\n",
       " 'and',\n",
       " 'enchman',\n",
       " 'ussian',\n",
       " 'others',\n",
       " 'in',\n",
       " 'eir',\n",
       " 'offences',\n",
       " 'and',\n",
       " 'in',\n",
       " 'eir',\n",
       " 'isaster',\n",
       " 'upon',\n",
       " 'ills',\n",
       " 'of',\n",
       " 'issago',\n",
       " 'eheld',\n",
       " 'in',\n",
       " 'eneva',\n",
       " 'at',\n",
       " 'other',\n",
       " 'end',\n",
       " 'of',\n",
       " 'itzerland',\n",
       " 'oor',\n",
       " 'ittle',\n",
       " 'eague',\n",
       " 'of',\n",
       " 'Allied',\n",
       " 'ations',\n",
       " 'excluding',\n",
       " 'United',\n",
       " 'ates',\n",
       " 'ussia',\n",
       " 'and',\n",
       " 'ost',\n",
       " 'of',\n",
       " 'ubject',\n",
       " 'eoples',\n",
       " 'of',\n",
       " 'orld',\n",
       " 'eeting',\n",
       " 'obscurely',\n",
       " 'amidst',\n",
       " 'orld',\n",
       " 'ide',\n",
       " 'isregard',\n",
       " 'ake',\n",
       " 'impotent',\n",
       " 'estures',\n",
       " 'at',\n",
       " 'eading',\n",
       " 'oblems',\n",
       " 'of',\n",
       " 'ebacle',\n",
       " 'Either',\n",
       " 'isaster',\n",
       " 'as',\n",
       " 'ot',\n",
       " 'een',\n",
       " 'ast',\n",
       " 'enough',\n",
       " 'et',\n",
       " 'or',\n",
       " 'it',\n",
       " 'as',\n",
       " 'ot',\n",
       " 'een',\n",
       " 'ift',\n",
       " 'enough',\n",
       " 'inflict',\n",
       " 'ecessary',\n",
       " 'oral',\n",
       " 'ock',\n",
       " 'and',\n",
       " 'achieve',\n",
       " 'ecessary',\n",
       " 'oral',\n",
       " 'evulsion',\n",
       " 'ust',\n",
       " 'as',\n",
       " 'orld',\n",
       " 'of',\n",
       " 'as',\n",
       " 'used',\n",
       " 'an',\n",
       " 'increasing',\n",
       " 'osperity',\n",
       " 'and',\n",
       " 'ought',\n",
       " 'at',\n",
       " 'increase',\n",
       " 'ould',\n",
       " 'on',\n",
       " 'or',\n",
       " 'ever',\n",
       " 'ow',\n",
       " 'it',\n",
       " 'ould',\n",
       " 'eem',\n",
       " 'orld',\n",
       " 'is',\n",
       " 'owing',\n",
       " 'accustomed',\n",
       " 'eady',\n",
       " 'ide',\n",
       " 'owards',\n",
       " 'ocial',\n",
       " 'isintegration',\n",
       " 'and',\n",
       " 'inks',\n",
       " 'at',\n",
       " 'at',\n",
       " 'oo',\n",
       " 'an',\n",
       " 'on',\n",
       " 'ontinually',\n",
       " 'and',\n",
       " 'ever',\n",
       " 'ome',\n",
       " 'inal',\n",
       " 'ump',\n",
       " 'oon',\n",
       " 'use',\n",
       " 'and',\n",
       " 'ont',\n",
       " 'establish',\n",
       " 'emselves',\n",
       " 'and',\n",
       " 'ost',\n",
       " 'aming',\n",
       " 'and',\n",
       " 'underous',\n",
       " 'of',\n",
       " 'essons',\n",
       " 'ale',\n",
       " 'into',\n",
       " 'isregard',\n",
       " 'uestion',\n",
       " 'ether',\n",
       " 'eblanc',\n",
       " 'is',\n",
       " 'ill',\n",
       " 'ossible',\n",
       " 'uestion',\n",
       " 'ether',\n",
       " 'it',\n",
       " 'is',\n",
       " 'ill',\n",
       " 'ossible',\n",
       " 'ing',\n",
       " 'about',\n",
       " 'an',\n",
       " 'outbreak',\n",
       " 'of',\n",
       " 'eative',\n",
       " 'anity',\n",
       " 'in',\n",
       " 'ankind',\n",
       " 'avert',\n",
       " 'is',\n",
       " 'eady',\n",
       " 'ide',\n",
       " 'estruction',\n",
       " 'is',\n",
       " 'ow',\n",
       " 'one',\n",
       " 'of',\n",
       " 'ost',\n",
       " 'urgent',\n",
       " 'in',\n",
       " 'orld',\n",
       " 'It',\n",
       " 'is',\n",
       " 'ear',\n",
       " 'at',\n",
       " 'iter',\n",
       " 'is',\n",
       " 'emperamentally',\n",
       " 'isposed',\n",
       " 'ope',\n",
       " 'at',\n",
       " 'ere',\n",
       " 'is',\n",
       " 'uch',\n",
       " 'ossibility',\n",
       " 'ut',\n",
       " 'as',\n",
       " 'onfess',\n",
       " 'at',\n",
       " 'ees',\n",
       " 'ew',\n",
       " 'igns',\n",
       " 'of',\n",
       " 'any',\n",
       " 'uch',\n",
       " 'eadth',\n",
       " 'of',\n",
       " 'understanding',\n",
       " 'and',\n",
       " 'eadfastness',\n",
       " 'of',\n",
       " 'ill',\n",
       " 'as',\n",
       " 'an',\n",
       " 'effectual',\n",
       " 'effort',\n",
       " 'urn',\n",
       " 'ush',\n",
       " 'of',\n",
       " 'uman',\n",
       " 'affairs',\n",
       " 'emands',\n",
       " 'inertia',\n",
       " 'of',\n",
       " 'ead',\n",
       " 'ideas',\n",
       " 'and',\n",
       " 'old',\n",
       " 'institutions',\n",
       " 'arries',\n",
       " 'us',\n",
       " 'on',\n",
       " 'owards',\n",
       " 'apids',\n",
       " 'Only',\n",
       " 'in',\n",
       " 'one',\n",
       " 'irection',\n",
       " 'is',\n",
       " 'ere',\n",
       " 'any',\n",
       " 'ain',\n",
       " 'ecognition',\n",
       " 'of',\n",
       " 'idea',\n",
       " 'of',\n",
       " 'uman',\n",
       " 'ommonweal',\n",
       " 'as',\n",
       " 'omething',\n",
       " 'overriding',\n",
       " 'any',\n",
       " 'ational',\n",
       " 'and',\n",
       " 'atriotic',\n",
       " 'onsideration',\n",
       " 'and',\n",
       " 'at',\n",
       " 'is',\n",
       " 'in',\n",
       " 'orking',\n",
       " 'ass',\n",
       " 'ovement',\n",
       " 'oughout',\n",
       " 'orld',\n",
       " 'And',\n",
       " 'abour',\n",
       " 'internationalism',\n",
       " 'is',\n",
       " 'osely',\n",
       " 'ound',\n",
       " 'up',\n",
       " 'ith',\n",
       " 'onceptions',\n",
       " 'of',\n",
       " 'ofound',\n",
       " 'ocial',\n",
       " 'evolution',\n",
       " 'If',\n",
       " 'orld',\n",
       " 'eace',\n",
       " 'is',\n",
       " 'attained',\n",
       " 'ough',\n",
       " 'abour',\n",
       " 'internationalism',\n",
       " 'it',\n",
       " 'ill',\n",
       " 'ave',\n",
       " 'attained',\n",
       " 'at',\n",
       " 'ice',\n",
       " 'of',\n",
       " 'ompletest',\n",
       " 'ocial',\n",
       " 'and',\n",
       " 'economic',\n",
       " 'econstruction',\n",
       " 'and',\n",
       " 'assing',\n",
       " 'ough',\n",
       " 'ase',\n",
       " 'of',\n",
       " 'evolution',\n",
       " 'at',\n",
       " 'ill',\n",
       " 'ertainly',\n",
       " 'iolent',\n",
       " 'at',\n",
       " 'ay',\n",
       " 'ery',\n",
       " 'oody',\n",
       " 'ich',\n",
       " 'ay',\n",
       " 'olonged',\n",
       " 'ough',\n",
       " 'ong',\n",
       " 'eriod',\n",
       " 'and',\n",
       " 'ay',\n",
       " 'in',\n",
       " 'end',\n",
       " 'ail',\n",
       " 'achieve',\n",
       " 'anything',\n",
       " 'ut',\n",
       " 'ocial',\n",
       " 'estruction',\n",
       " 'evertheless',\n",
       " 'act',\n",
       " 'emains',\n",
       " 'at',\n",
       " 'it',\n",
       " 'is',\n",
       " 'in',\n",
       " 'abour',\n",
       " 'ass',\n",
       " 'and',\n",
       " 'abour',\n",
       " 'ass',\n",
       " 'alone',\n",
       " 'at',\n",
       " 'any',\n",
       " 'onception',\n",
       " 'of',\n",
       " 'orld',\n",
       " 'ule',\n",
       " 'and',\n",
       " 'orld',\n",
       " 'eace',\n",
       " 'as',\n",
       " 'ar',\n",
       " 'appeared',\n",
       " 'eam',\n",
       " 'of',\n",
       " 'orld',\n",
       " 'et',\n",
       " 'ee',\n",
       " 'eam',\n",
       " 'of',\n",
       " 'ighly',\n",
       " 'educated',\n",
       " 'and',\n",
       " 'ighly',\n",
       " 'avoured',\n",
       " 'eading',\n",
       " 'and',\n",
       " 'uling',\n",
       " 'en',\n",
       " 'oluntarily',\n",
       " 'etting',\n",
       " 'emselves',\n",
       " 'ask',\n",
       " 'of',\n",
       " 'eshaping',\n",
       " 'orld',\n",
       " 'as',\n",
       " 'us',\n",
       " 'ar',\n",
       " 'emained',\n",
       " 'eam',\n",
       " 'ELLS',\n",
       " 'EASTON',\n",
       " 'EBE',\n",
       " 'UNMOW',\n",
       " 'ONTENTS',\n",
       " 'ELUDE',\n",
       " 'UN',\n",
       " 'ARERS',\n",
       " 'APTER',\n",
       " 'IRST',\n",
       " 'EW',\n",
       " 'OURCE',\n",
       " 'OF',\n",
       " 'ENERGY',\n",
       " 'APTER',\n",
       " 'ECOND',\n",
       " 'AST',\n",
       " 'AR',\n",
       " 'APTER',\n",
       " 'IRD',\n",
       " 'ENDING',\n",
       " ...]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "search_pattern = r'[aeiouAEIOU]\\w+'\n",
    "vowel = re.findall(search_pattern, file_contents)\n",
    "vowel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regular expression (sometimes called a rational expression) is a sequence of characters that define a search pattern, mainly for use in pattern matching with strings, or string matching. A regular expression is a method used in programming for pattern matching. Regular expressions provide a flexible and concise means to match strings of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57187\n"
     ]
    }
   ],
   "source": [
    "print(len(vowel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tagging is the process of marking up a word in a corpus to a corresponding part of a speech tag, based on its context and definition. This task is not straightforward, as a particular word may have a different part of speech based on the context in which the word is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The                  DET                  determiner\n",
      "question             NOUN                 noun\n",
      "whether              ADP                  adposition\n",
      "a                    DET                  determiner\n",
      "Leblanc              PROPN                proper noun\n",
      "is                   VERB                 verb\n",
      "still                ADV                  adverb\n",
      "possible             ADJ                  adjective\n",
      ",                    PUNCT                punctuation\n",
      "the                  DET                  determiner\n",
      "question             NOUN                 noun\n",
      "whether              ADP                  adposition\n",
      "\n",
      "                    SPACE                space\n"
     ]
    }
   ],
   "source": [
    "for token in doc_object:\n",
    "    #show token\n",
    "    print(f\"{token.text:{20}} {token.pos_:{20}} {spacy.explain(token.pos_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In natural language processing, useless words (data), are referred to as stop words. ... Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=file_contents[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_object = nlp(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The Project Gutenberg EBook of The World Set Free, by Herbert George Wells\n",
       "\n",
       "This eBook is for the use of anyone anywhere at no cost and with\n",
       "almost no restrictions whatsoever.  You may copy it, give it away or\n",
       "re-use it under the terms of the Project Gutenberg License included\n",
       "with this eBook or online at www.gutenberg.org\n",
       "\n",
       "\n",
       "Title: The World Set Free\n",
       "\n",
       "Author: Herbert George Wells\n",
       "\n",
       "Release Date: February 11, 2006 [EBook #1059]\n",
       "Last Updated: September 17, 2016\n",
       "\n",
       "Language: English\n",
       "\n",
       "Character set enc"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library\n",
    "# declaing a list to save all stop words\n",
    "stop_words = []\n",
    "\n",
    "# appending all stop words to the list\n",
    "for word in doc_object:\n",
    "        if word.is_stop == True:\n",
    "            stop_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[of, by, is, for, the, of, anyone, anywhere, at, no, and, with, almost, no, may, it, give, it, or, re, it, under, the, of, the, with, this, or, at, by, and, was, in, and, in, and, it, is, the, of, a, of, three, of, which, all, on, the, in, the, of, some, or, of, was, under, the, of, the, in, the, that, was, and, no, of, it, but, few, of, us, in, the, of, how, the, was, to, us, will, be, to, that, here, it, is, put, off, until, the, may, to, the, for, what, will, seem, now, a, quite, a, the, must, he, has, always, been, to, be, rather, a, in, the, of, for, the, in, by, about, twenty, or, so, a, not, to, the, of, and, and, perhaps, a, less, to, have, something, to, do, with, this, of, one, but, in, the, of, there, was, another, in, the, back, and, that, was, to, the, to, get, well, with, his, of, the, of, for, that, be, none, too, for, that, in, from, this, of, over, forty, the, at, the, of, the, was, the, of, an, of, the, the, through, the, and, the, of, the, were, all, before, the, had, been, six, the, of, the, now, after, the, has, a, of, the, of, the, in, the, on, which, the, may, himself, is, the, that, under, it, would, be, quite, for, any, to, to, and, the, of, the, of, either, side, could, be, no, or, we, the, as, it, is, here, however, are, and, the, in, the, the, is, the, which, is, still, of, now, the, that, because, of, the, of, and, are, no, in, the, that, to, to, keep, on, with, the, is, to, upon, for, and, perhaps, to, our, of, this, now, is, the, of, this, and, the, of, the, of, on, the, have, a, of, of, to, out, among, the, of, and, the, of, have, the, of, the, and, of, the, for, is, to, be, towards, a, and, of, and, of, which, as, the, say, to, of, a, and, of, and, in, their, and, in, their, upon, the, of, in, at, the, other, of, a, of, the, and, most, of, the, of, the, a, to, make, at, the, of, the, the, has, not, been, enough, yet, or, it, has, not, been, enough, to, the, and, the, as, the, of, was, used, to, an, and, that, would]\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing two stop words from vocab\n",
    "\n",
    "nlp.vocab['for'].is_stop = False\n",
    "nlp.vocab['The'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaing a list to save all stop words\n",
    "stop_words_after = []\n",
    "\n",
    "# appending all stop words to the list\n",
    "for word in doc_object:\n",
    "        if word.is_stop == True:\n",
    "            stop_words_after.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[of, is, the, of, anyone, anywhere, at, no, and, with, almost, no, may, it, give, it, or, re, it, under, the, of, the, with, this, or, at, and, was, in, and, in, and, it, is, the, of, a, of, three, of, which, all, on, the, in, the, of, some, or, of, was, under, the, of, the, in, the, that, was, and, no, of, it, but, few, of, us, in, the, of, how, the, was, to, us, will, be, to, that, here, it, is, put, off, until, the, may, to, the, what, will, seem, now, a, quite, a, the, must, he, has, always, been, to, be, rather, a, in, the, of, the, in, about, twenty, or, so, a, not, to, the, of, and, and, perhaps, a, less, to, have, something, to, do, with, this, of, one, but, in, the, of, there, was, another, in, the, back, and, that, was, to, the, to, get, well, with, his, of, the, of, that, be, none, too, that, in, from, this, of, over, forty, the, at, the, of, the, was, the, of, an, of, the, the, through, the, and, the, of, the, were, all, before, the, had, been, six, the, of, the, now, after, the, has, a, of, the, of, the, in, the, on, which, the, may, himself, is, the, that, under, it, would, be, quite, any, to, to, and, the, of, the, of, either, side, could, be, no, or, we, the, as, it, is, here, however, are, and, the, in, the, the, is, the, which, is, still, of, now, the, that, because, of, the, of, and, are, no, in, the, that, to, to, keep, on, with, the, is, to, upon, and, perhaps, to, our, of, this, now, is, the, of, this, and, the, of, the, of, on, the, have, a, of, of, to, out, among, the, of, and, the, of, have, the, of, the, and, of, the, is, to, be, towards, a, and, of, and, of, which, as, the, say, to, of, a, and, of, and, in, their, and, in, their, upon, the, of, in, at, the, other, of, a, of, the, and, most, of, the, of, the, a, to, make, at, the, of, the, the, has, not, been, enough, yet, or, it, has, not, been, enough, to, the, and, the, as, the, of, was, used, to, an, and, that, would]\n"
     ]
    }
   ],
   "source": [
    "print(stop_words_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A named entity is a real-world object that’s assigned a name – for example, a person, a country, a product, a date, money, a book title etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=file_contents[:5000]\n",
    "doc_object = nlp(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_entity_info(doc_object):\n",
    "    if doc_object:\n",
    "        for entity in doc_object.ents:\n",
    "            print(f\"{entity.text:{30}} {entity.label_:{30}} {spacy.explain(entity.label_):{30}}\")\n",
    "    else:\n",
    "        print(f\"No entities found in text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The World Set Free             ORG                            Companies, agencies, institutions, etc.\n",
      "Herbert George Wells           PERSON                         People, including fictional   \n",
      "eBook                          ORG                            Companies, agencies, institutions, etc.\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "the Project Gutenberg License  ORG                            Companies, agencies, institutions, etc.\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "eBook                          ORG                            Companies, agencies, institutions, etc.\n",
      "\n",
      "\n",
      "\n",
      "Title                       ORG                            Companies, agencies, institutions, etc.\n",
      "The World Set Free\n",
      "\n",
      "           ORG                            Companies, agencies, institutions, etc.\n",
      "Herbert George Wells\n",
      "\n",
      "Release Date PERSON                         People, including fictional   \n",
      "February 11, 2006              DATE                           Absolute or relative dates or periods\n",
      "EBook                          ORG                            Companies, agencies, institutions, etc.\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "September 17, 2016             DATE                           Absolute or relative dates or periods\n",
      "English                        LANGUAGE                       Any named language            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced                  ORG                            Companies, agencies, institutions, etc.\n",
      "Charles Keller                 PERSON                         People, including fictional   \n",
      "David Widger                   PERSON                         People, including fictional   \n",
      "THE WORLD SET FREE             ORG                            Companies, agencies, institutions, etc.\n",
      "All Things That Make           WORK_OF_ART                    Titles of books, songs, etc.  \n",
      "A Hidden Mission,\n",
      "             WORK_OF_ART                    Titles of books, songs, etc.  \n",
      "The Open Sea                   LOC                            Non-GPE locations, mountain ranges, bodies of water\n",
      "Frederick Soddy                PERSON                         People, including fictional   \n",
      "Owes                           ORG                            Companies, agencies, institutions, etc.\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "Book, Acknowledges             ORG                            Companies, agencies, institutions, etc.\n",
      "Inscribes                      ORG                            Companies, agencies, institutions, etc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                          ORG                            Companies, agencies, institutions, etc.\n",
      "SET FREE                       ORG                            Companies, agencies, institutions, etc.\n",
      "1913                           DATE                           Absolute or relative dates or periods\n",
      "1914                           DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "three                          CARDINAL                       Numerals that do not fall under another type\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "The World Set Free             ORG                            Companies, agencies, institutions, etc.\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "the Great War                  EVENT                          Named hurricanes, battles, wars, sports events, etc.\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "the earlier half of 1914       DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "the year 1956                  DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "Anticipations                  ORG                            Companies, agencies, institutions, etc.\n",
      "about twenty years             DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "one                            CARDINAL                       Numerals that do not fall under another type\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "The World Set Free             ORG                            Companies, agencies, institutions, etc.\n",
      "\n",
      "the Great War                 EVENT                          Named hurricanes, battles, wars, sports events, etc.\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "1956                           DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "2056                           DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "forty\n",
      "years                    DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "the Central Empires            ORG                            Companies, agencies, institutions, etc.\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "Netherlands                    GPE                            Countries, cities, states     \n",
      "the British Expeditionary\n",
      "Force ORG                            Companies, agencies, institutions, etc.\n",
      "six months                     DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "Chapter the                    LAW                            Named documents made into laws.\n",
      "Second                         ORDINAL                        \"first\", \"second\", etc.       \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "One                            CARDINAL                       Numerals that do not fall under another type\n",
      "Second                         ORDINAL                        \"first\", \"second\", etc.       \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "French                         NORP                           Nationalities or religious or political groups\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "English                        NORP                           Nationalities or religious or political groups\n",
      "Egbert                         PERSON                         People, including fictional   \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "to-day’s                       DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "German                         NORP                           Nationalities or religious or political groups\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "Russian                        NORP                           Nationalities or religious or political groups\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "Brissago                       GPE                            Countries, cities, states     \n",
      "Geneva                         GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "Switzerland                    GPE                            Countries, cities, states     \n",
      "little League of (             ORG                            Companies, agencies, institutions, etc.\n",
      "Allied) Nations                ORG                            Companies, agencies, institutions, etc.\n",
      "the\n",
      "United States              GPE                            Countries, cities, states     \n",
      "Russia                         GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "\n",
      "                              GPE                            Countries, cities, states     \n",
      "1913                           DATE                           Absolute or relative dates or periods\n",
      "\n",
      "                              GPE                            Countries, cities, states     \n"
     ]
    }
   ],
   "source": [
    "show_entity_info(doc_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "sentences=file_contents[:50000]\n",
    "doc_object = nlp(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match for \"man\"\n",
    "token_match1 = [{\"LOWER\": \"man\"}]\n",
    "# match for \"woman\"\n",
    "token_match2 = [{\"LOWER\": \"woman\"}]\n",
    "\n",
    "matcher.add(\"gender\", None, token_match1, token_match2)\n",
    "token_matches = matcher(doc_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Matched Text:             Text starts at:       1530   Text ends at:       1531 \n",
      " Matched Text:             Text starts at:       1706   Text ends at:       1707 \n",
      " Matched Text:             Text starts at:       1743   Text ends at:       1744 \n",
      " Matched Text:             Text starts at:       1789   Text ends at:       1790 \n",
      " Matched Text:             Text starts at:       2122   Text ends at:       2123 \n",
      " Matched Text:             Text starts at:       2147   Text ends at:       2148 \n",
      " Matched Text:             Text starts at:       2239   Text ends at:       2240 \n",
      " Matched Text:             Text starts at:       2341   Text ends at:       2342 \n",
      " Matched Text:             Text starts at:       2744   Text ends at:       2745 \n",
      " Matched Text:             Text starts at:       2921   Text ends at:       2922 \n",
      " Matched Text:             Text starts at:       2945   Text ends at:       2946 \n",
      " Matched Text:             Text starts at:       3029   Text ends at:       3030 \n",
      " Matched Text:             Text starts at:       3159   Text ends at:       3160 \n",
      " Matched Text:             Text starts at:       3230   Text ends at:       3231 \n",
      " Matched Text:             Text starts at:       3241   Text ends at:       3242 \n",
      " Matched Text:             Text starts at:       4382   Text ends at:       4383 \n",
      " Matched Text:             Text starts at:       4449   Text ends at:       4450 \n",
      " Matched Text:             Text starts at:       4689   Text ends at:       4690 \n",
      " Matched Text:             Text starts at:       5075   Text ends at:       5076 \n",
      " Matched Text:             Text starts at:       5603   Text ends at:       5604 \n",
      " Matched Text:             Text starts at:       5711   Text ends at:       5712 \n",
      " Matched Text:             Text starts at:       5908   Text ends at:       5909 \n",
      " Matched Text:             Text starts at:       6414   Text ends at:       6415 \n",
      " Matched Text:             Text starts at:       6463   Text ends at:       6464 \n",
      " Matched Text:             Text starts at:       6546   Text ends at:       6547 \n",
      " Matched Text:             Text starts at:       6789   Text ends at:       6790 \n",
      " Matched Text:             Text starts at:       6830   Text ends at:       6831 \n",
      " Matched Text:             Text starts at:       7960   Text ends at:       7961 \n",
      " Matched Text:             Text starts at:       7964   Text ends at:       7965 \n",
      " Matched Text:             Text starts at:       8108   Text ends at:       8109 \n",
      " Matched Text:             Text starts at:       8316   Text ends at:       8317 \n",
      " Matched Text:             Text starts at:       8467   Text ends at:       8468 \n",
      " Matched Text:             Text starts at:       8739   Text ends at:       8740 \n",
      " Matched Text:             Text starts at:       8741   Text ends at:       8742 \n",
      " Matched Text:             Text starts at:       8773   Text ends at:       8774 \n",
      " Matched Text:             Text starts at:       8812   Text ends at:       8813 \n",
      " Matched Text:             Text starts at:      10494   Text ends at:      10495 \n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "\n",
    "for match_id, start, end in token_matches:\n",
    "        matched_text = str(doc_object[start:end])\n",
    "        total_count += 1\n",
    "        print(f' Matched Text: {matched_text:{10}}  Text starts at: {start:{10}}   Text ends at: {end:{10}} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PhraseMatcher \n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Matched Text: happy                 Text starts at:                  607          Text ends at:        608 5 Words Before and After -> \n",
      "the matter. One happy hit (in Chapter the\n",
      " Matched Text: happy                 Text starts at:                 7046          Text ends at:       7047 5 Words Before and After -> rather\n",
      "a procession of happy accidents than an orderly conquest\n",
      " Matched Text: happy                 Text starts at:                 7379          Text ends at:       7380 5 Words Before and After -> phenomena. It was a happy association for his inquiries.\n",
      " Matched Text: happy                 Text starts at:                10417          Text ends at:      10418 5 Words Before and After -> fairly prosperous, fairly\n",
      "happy, fairly well adapted to\n"
     ]
    }
   ],
   "source": [
    "sentences=file_contents[:50000]\n",
    "doc_object = nlp(sentences)\n",
    "\n",
    "given_words = ('laugh', 'cry', 'happy', 'sad')\n",
    "\n",
    "phrase_patterns = [nlp.make_doc(word) for word in given_words]\n",
    "\n",
    "phrase_matcher.add('Phrase Matcher', None, *phrase_patterns)\n",
    "matches = phrase_matcher(doc_object)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "        matched_text = str(doc_object[start:end])\n",
    "        span = str(doc_object[start-5 : end + 5])\n",
    "        print(f' Matched Text: {matched_text:{20}}  Text starts at: {start:{20}}  \\\n",
    "        Text ends at: {end:{10}} 5 Words Before and After -> {span}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD - The \t LEMMA - the\n",
      "WORD - Project \t LEMMA - project\n",
      "WORD - Gutenberg \t LEMMA - gutenberg\n",
      "WORD - EBook \t LEMMA - ebook\n",
      "WORD - of \t LEMMA - of\n",
      "WORD - The \t LEMMA - the\n",
      "WORD - World \t LEMMA - world\n",
      "WORD - Set \t LEMMA - set\n",
      "WORD - Free \t LEMMA - free\n",
      "WORD - , \t LEMMA - ,\n",
      "WORD - by \t LEMMA - by\n",
      "WORD - Herbert \t LEMMA - herbert\n",
      "WORD - George \t LEMMA - george\n",
      "WORD - Wells \t LEMMA - wells\n",
      "WORD - This \t LEMMA - this\n",
      "WORD - eBook \t LEMMA - ebook\n",
      "WORD - is \t LEMMA - be\n",
      "WORD - for \t LEMMA - for\n",
      "WORD - the \t LEMMA - the\n",
      "WORD - us \t LEMMA - -PRON-\n"
     ]
    }
   ],
   "source": [
    "# Selecting a sentence \n",
    "\n",
    "sentences=file_contents[:100]\n",
    "doc_object = nlp(sentences)\n",
    "\n",
    "# Printing the word and its Lemma\n",
    "for word in doc_object:\n",
    "    if word.is_space != True:\n",
    "        print ('WORD -', word.text, '\\t',  'LEMMA -' , word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1850\" height=\"362.0\" style=\"max-width: none; height: 362.0px; color: black; background: yellow; font-family: calibri\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">Project</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">Gutenberg</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">EBook</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">World</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">Set</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">Free,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">Herbert</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">George</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">Wells</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1220\">\n",
       "\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1220\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1310\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1310\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">eBook</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1580\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1580\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1670\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1670\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1760\">us</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1760\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M62,227.0 62,182.0 314.0,182.0 314.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,229.0 L58,221.0 66,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M152,227.0 152,197.0 311.0,197.0 311.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M152,229.0 L148,221.0 156,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M242,227.0 242,212.0 308.0,212.0 308.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M242,229.0 L238,221.0 246,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M332,227.0 332,212.0 398.0,212.0 398.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M398.0,229.0 L402.0,221.0 394.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M512,227.0 512,182.0 764.0,182.0 764.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M512,229.0 L508,221.0 516,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M602,227.0 602,197.0 761.0,197.0 761.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M602,229.0 L598,221.0 606,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M692,227.0 692,212.0 758.0,212.0 758.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M692,229.0 L688,221.0 696,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M422,227.0 422,167.0 767.0,167.0 767.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M767.0,229.0 L771.0,221.0 763.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M332,227.0 332,152.0 860.0,152.0 860.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M860.0,229.0 L864.0,221.0 856.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M962,227.0 962,197.0 1121.0,197.0 1121.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M962,229.0 L958,221.0 966,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-10\" stroke-width=\"2px\" d=\"M1052,227.0 1052,212.0 1118.0,212.0 1118.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1052,229.0 L1048,221.0 1056,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-11\" stroke-width=\"2px\" d=\"M872,227.0 872,182.0 1124.0,182.0 1124.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-11\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1124.0,229.0 L1128.0,221.0 1120.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-12\" stroke-width=\"2px\" d=\"M1142,227.0 1142,212.0 1208.0,212.0 1208.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-12\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1208.0,229.0 L1212.0,221.0 1204.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-13\" stroke-width=\"2px\" d=\"M1322,227.0 1322,212.0 1388.0,212.0 1388.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-13\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1322,229.0 L1318,221.0 1326,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-14\" stroke-width=\"2px\" d=\"M1412,227.0 1412,212.0 1478.0,212.0 1478.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-14\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1412,229.0 L1408,221.0 1416,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-15\" stroke-width=\"2px\" d=\"M1502,227.0 1502,212.0 1568.0,212.0 1568.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-15\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1568.0,229.0 L1572.0,221.0 1564.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-16\" stroke-width=\"2px\" d=\"M1682,227.0 1682,212.0 1748.0,212.0 1748.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-16\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1682,229.0 L1678,221.0 1686,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-17\" stroke-width=\"2px\" d=\"M1592,227.0 1592,197.0 1751.0,197.0 1751.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-17\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1751.0,229.0 L1755.0,221.0 1747.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc_object, style='dep', jupyter=True, options={'distance': 90,\n",
    "                                                              'compact' : True,\n",
    "                                                              'color':'black', \n",
    "                                                              'bg' : 'yellow',\n",
    "                                                              'font':'calibri'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
